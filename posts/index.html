<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | ZZNEWCLEAR13</title><meta name=keywords content><meta name=description content="这里是zznewclear13.com"><meta name=author content="zznewclear13"><link rel=canonical href=https://zznewclear13.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.min.05062af87031756c80e5d65f0cc75e37e589bbf77383569463393b1f73d94f87.css integrity="sha256-BQYq+HAxdWyA5dZfDMdeN+WJu/dzg1aUYzk7H3PZT4c=" rel="preload stylesheet" as=style><link rel=preload href=/images/address.png as=image><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://zznewclear13.github.io/favicon.ico><link rel=apple-touch-icon href=https://zznewclear13.github.io/favicon.ico><link rel=mask-icon href=https://zznewclear13.github.io/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><link rel=alternate type=application/rss+xml href=https://zznewclear13.github.io/posts/index.xml><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-157509723-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Posts"><meta property="og:description" content="这里是zznewclear13.com"><meta property="og:type" content="website"><meta property="og:url" content="https://zznewclear13.github.io/posts/"><meta property="og:image" content="https://zznewclear13.github.io/images/address.png"><meta property="og:site_name" content="ZZNEWCLEAR13 - Should I say something cool here?"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zznewclear13.github.io/images/address.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="这里是zznewclear13.com"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zznewclear13.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://zznewclear13.github.io/ accesskey=h title="ZZNEWCLEAR13 (Alt + H)"><img src=/apple-touch-icon.png alt=logo aria-label=logo height=35>ZZNEWCLEAR13</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://zznewclear13.github.io/now/ title=进行时><span>进行时</span></a></li><li><a href=https://zznewclear13.github.io/memos/ title=备忘录><span>备忘录</span></a></li><li><a href=https://zznewclear13.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://zznewclear13.github.io/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://zznewclear13.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/GTAO.jpg alt="Ground Truth Ambient Occlusion Cover"></figure><header class=entry-header><h2>Unity使用ComputeShader计算GTAO</h2></header><section class=entry-content><p>环境光遮蔽 环境光遮蔽，在很久很久以前玩刺客信条的时候就看到过这个词语，但是并不懂什么意思，本着画质拉满的原则总是会勾选这个选项。后来才知道环境光遮蔽翻译自Ambient Occlusion（还真是直白的翻译），用来表现角落里阴暗的效果。
环境光遮蔽作用在光线计算的间接光照的阶段，由于光栅化渲染的局限性，间接光照往往分为漫反射间接光照和高光间接光照，因此环境光遮蔽也分漫反射和高光两种，这里暂时只讨论作用于漫反射间接光照的漫反射环境光遮蔽。而又由于前向渲染的局限性，屏幕空间的环境光遮蔽不分差别地作用于直接光照和间接光照，因此其强度还需要特别地留意。
Ground Truth Ambient Occlusion是Jorge Jimenez在他的文章Practical Real-Time Strategies for Accurate Indirect Occlusion中介绍的一种在主机上能够符合事实环境光遮蔽效果的一种屏幕空间环境光遮蔽的算法。我认为这个算法相较于其他的环境光遮蔽的算法最大的优点是，暗部够暗，在很窄的缝隙中能够很黑很黑，这是别的算法做不到的。
本文极大地参考了英特尔的XeGTAO开源代码。
具体的操作 这篇文章着重要讲的是使用Compute Shader来加速计算的操作方式，因此不会具体涉及到GTAO算法本身，感兴趣的话可以去SIGGRAPH 2016 Course上阅读GTAO的ppt。
GTAO的计算需要视空间法线和深度两个数据，如果是延迟管线的话能轻易得拿到所有数据，但对于前向渲染来说，需要从深度数据还原出视空间法线。正好我之前的文章介绍了一些从深度图计算视空间法线的方法。但在原有文章的基础上，我们还能使用Group Shared Memory对采样数进行一系列的优化。
由于GTAO相对来说算是比较低频的信息，我们可以考虑使用下采样的方式只用半分辨率甚至是更低的分辨率来计算GTAO。这里使用的方法是对NxN大小的区域，每一帧只取一个采样点，最后通过TAA来进行混合。
GTAO本身的采样数也能使用时空噪声来生成较少的采样点，最后通过TAA来进行混合。但是实际使用中发现，如果使用较多的时间混合，当场景中的物体发生移动之后，会露出一部分白色的画面，和较深的AO有比较明显的对比，因此考虑尽量多地使用空间的混合。
得益于Group Shared Memory，可以在非常大的范围内进行空间的混合，这里使用高斯模糊的方式进行混合，能够尽量保持暗部较暗的颜色。如果直接对所有的采样进行平均的话，会导致暗部变得很亮，失去了GTAO最出众的优点。对水平和竖直方向做两次高斯模糊的话，由于本身还会根据深度和法线算出额外的几何上的权重，在下采样程度较大的时候会产生比较明显的瑕疵，可以用全分辨率的深度图和法线来解决，但这会带来额外的采样。
在高斯模糊的阶段，由于模糊是作用在低分辨率的图像上的，在我们的上采样的操作中，还需要根据上采样的位置进行双线性插值（实际上只要一个方向线性插值就好了）。
Render Texture的精度上，GTAO最后的值可以用8位通道来储存，如果不需要额外的视空间法线的话，可以把GTAO值和24位的深度一起存到RGBA32的RT中。这里就偷懒使用R16G16B16A16_SFloat来储存了。
如此一来整个路线图就比较清晰了
下采样深度图获取深度数据 使用深度图计算视空间的法线，或者从G Buffer直接获取法线数据 使用深度图和法线计算GTAO的值 横向上采样，计算水平高斯模糊后的GTAO的值 纵向上采样，计算垂直高斯模糊后的GTAO的值 相关代码和说明 GTAOComputeShader.compute 重中之重就是Compute Shader了。分了四个Kernel：第一个计算GTAO的值，同时还储存了深度图和法线（除了直接储存法线的两个分量，也可以Encode成八面体来储存）；第二个和第三个分别是水平和竖直方向的模糊；最后一个用来可视化，实际项目中可以不用这个。
和XeGTAO不同的是，我增加了一个USE_AVERAGE_COS的宏，正常是在每一个Slice中选择最大的cos值，但是考虑到场景中有栅格这样的物体，在时空混合程度不是很大的时候，可以计算cos的平均值来降低栅格对GTAO的影响（也就是减弱了噪声），这个宏完全可以不用开启。
本文为了尽量多的使用空间混合（亦即不使用时间混合），在XeGTAO的时空平均噪波中限制了时间的参数为13，这样GTAO就不会随着时间而变化了，实际上可以传入_FrameIndex充分利用时空噪波的优势。
主要是用groupIndex来储存和读取Group Shared Memory，每个点至多采样两次。计算法线时会采样5x5的区域，因此NORMAL_FROM_DEPTH_PIXEL_RANGE的值是2；计算模糊时既有高斯模糊的采样，还有后续手动线性插值的采样，所以CACHED_AO_NORMAL_DEPTH_FOR_BLUR_SIZE会有两者之和。线性插值还需要注意subpixelBias对线性插值的权重产生的影响。
本文使用了宽度为29的高斯核，可以在demofox的网站上轻松的计算很大的高斯核。
可能会有报寄存器使用数量超过限制的问题，感觉是const array和循环导致的，不过reimport之后就不会报这个警告了。
#pragma kernel GTAOMain
#pragma kernel BlurHorizontalMain
#pragma kernel BlurVerticalMain
#pragma kernel VisualizeMain
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
Texture2D&lt;float4> _ColorTexture;
Texture2D&lt;float> _DepthTexture;
Texture2D&lt;float4> _GTAOTexture;
RWTexture2D&lt;float4> _RW_NormalTexture;
RWTexture2D&lt;float4> _RW_GTAOTexture;
RWTexture2D&lt;float4> _RW_BlurTexture;
RWTexture2D&lt;float4> _RW_VisualizeTexture;
SamplerState sampler_LinearClamp;
SamplerState sampler_PointClamp;
//region Parameters
uint _FrameIndex;
uint _DownsamplingFactor;
float _Intensity;
float _SampleRadius;
float _DistributionPower;
float _FalloffRange;
float2 _HeightFogFalloff;
float4 _TextureSize;
float4 _TAAOffsets;
//endregion
//region Pre-defined Marcos
#define SQRT2_2 0....</p></section><footer class=entry-footer>December 2, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to Unity使用ComputeShader计算GTAO" href=https://zznewclear13.github.io/posts/unity-ground-truth-ambient-occlusion/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/VolumetricFogRayMarched.jpg alt="Ray Marched Volumetric Fog Cover"></figure><header class=entry-header><h2>使用Ray Marching来渲染体积雾</h2></header><section class=entry-content><p>为什么要用Ray Marching 要不还是别用Ray Marching了（除非是SDF Ray Marching），采样次数又多又不好debug，不过写起来比较快（如果要写二分法的话就又复杂了）。如前文所说，使用Ray Marching的体积雾只能在后处理阶段使用了，在处理不写深度的透明物体的时候，会有一些瑕疵。
体积雾相关的就参考前文就好了，这里只是作为一个方法的补充。
相关代码和说明 为了和使用3D纹理的体积雾作区分，这边所有代码的名字前加上了RM(Ray Marching)。
RMVolumetricFog.cs 这个脚本和3D纹理的体积雾的参数几乎完全一致，只是多了用于控制Ray Marching次数的step。
using System; namespace UnityEngine.Rendering.Universal { [Serializable, VolumeComponentMenu("Post-processing/RM Volumetric Fog")] public class RMVolumetricFog : VolumeComponent, IPostProcessComponent { [Tooltip("是否启用体积雾")] public BoolParameter enabled = new BoolParameter(false); [Tooltip("整体控制体积雾强度")] public ClampedFloatParameter intensity = new ClampedFloatParameter(1.0f, 0f, 1.0f); [Tooltip("体积雾最大的透明程度（用于和天空混合）")] public ClampedFloatParameter maxTransmittance = new ClampedFloatParameter(1.0f, 0f, 1.0f); [Tooltip("体积雾的颜色倾向，目前强度为0.03")] public ColorParameter fogTint = new ColorParameter(Color.white); [Tooltip("体积雾距离相机最近的距离")] public ClampedFloatParameter fogNear = new ClampedFloatParameter(0.1f, 0.01f, 10f); [Tooltip("体积雾距离相机最远的距离")] public ClampedFloatParameter fogFar = new ClampedFloatParameter(100f, 1....</p></section><footer class=entry-footer>August 24, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用Ray Marching来渲染体积雾" href=https://zznewclear13.github.io/posts/create-volumetric-fog-using-ray-marching/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/VolumetricFog.jpg alt="Volumetric Fog Cover"></figure><header class=entry-header><h2>使用和视锥体对齐的3D纹理来渲染体积雾</h2></header><section class=entry-content><p>为什么要渲染体积雾 因为它就在那里。
当然了，更重要的是因为体积雾能迅速的营造出场景的真实感与氛围感，谁不喜欢光源边上还有一小圈光晕呢，如果什么高亮的物体都能影响体积雾的话，是不是就不太需要bloom效果了呢。我实际地在生活中观察了一下，发现人眼所看到的光晕的效果，是光线进入眼睛之后产生的，也就是说bloom和体积雾确确实实是两种不同的效果。
体积雾的渲染方法 体积雾一般有两种渲染方法，一种是单纯的从相机出发对场景进行Ray Marching，每次进行采样和混合。这种方法主要的缺点是Ray Marching的次数会比较高才能有较好的渲染效果。在我的测试中，开启TAA的时候，20次Ray Marching就能得到很好的体积雾效果了；但是不开启TAA的话，可能会需要60次甚至更高的Ray Marching才能得到和TAA类似的效果。同时，Ray Marching体积雾只能在后处理阶段使用，在处理不写深度的透明物体的时候，会有一些瑕疵。
另一种方法就是使用一张3D纹理，将整个场景的体积雾储存在这张3D纹理中，当绘制物体的时候使用物体的世界空间坐标采样这张3D纹理，直接在片元着色器中计算雾效之后的颜色。这种方法使用的3D纹理会占用更多的内存，但是一定程度上能够正确的渲染所有物体，和60次Ray Marching相比，性能上也说不定会有一些优势。
本文的体积雾实现，参考了EA的寒霜引擎在Siggraph 2015年时的演讲和diharaw的OpenGL的体积雾效果。值得一看的还有Bart Wronski在Siggraph 2014年的演讲，以及之后的荒野大镖客在Siggraph 2019年的课程。使用的是Unity2019.4.29的URP工程。
具体的实现方法 将场景中的需要渲染的雾的信息和阴影信息储存到一张和相机的视锥体对齐的3D纹理中。按照寒霜引擎的做法，纹理大小为(分辨率宽/8)x(分辨率高/8)x64，这样就和屏幕大小的2D纹理占用的内存大小一致了，但我看Unity官方的体积雾工程中，3D纹理的深度为128，就也把自己的设置成128了，纹理深度越深，体积雾的细节就能越高。3D纹理的宽高和视锥体对齐，这很好理解，而这张贴图的纵向深度和实际的深度要怎么对齐呢？最简单的就是和视空间的深度线性对应，但是这会导致近处体积雾的分辨率不够；另一种是和裁剪空间的深度线性对应，经过一些分析可以知道这比之前的方法更糟糕；目前我看下来最好的应该是和视空间的深度指数型对应，这样离相机越近3D纹理的像素会越多，越远则越少。本文只使用了均一的雾，但是可以使用世界空间的坐标、噪波和一系列的运算，计算出某一点的体积雾的浓度。 使用上面的雾的信息和阴影信息计算出散射的值Lscat，从下面的图可以看到Lscat是对所有的光源（本文只有主光源）计算\(f(v, l)Vis(x, l)Li(x, l)\)的和，\(Vis(x, l)\)即为在x点l光的可见性，可以通过采样阴影贴图来获得，\(Li(x, l)\)即为在x点l光的光强，可以简单的计算获得，\(f(v, l)\)用来表述在v的方向观察雾时得到l的散射量，一般被叫做Phase Function，我们使用的是Henyey-Greenstein Phase Function，其中参数g是雾的各向异性的程度，越靠近1表示光线穿过雾时越保持之前的方向，越靠近0表示光线穿过雾时均匀的散射，越靠近-1表示光线穿过雾时越会进行反射（在实际的光照中，我们会去掉\(\pi\)这一项，这样能和Unity的光照模型保持一致）。时空混合也在这一步可以完成。 $$ \tag{Henyey-Greenstein} p(\theta) = \frac 1 {4\pi} \frac {1 - g^2} {(1 + g^2 - 2g \cos \theta)^{\frac 3 2}} $$
对3D纹理从相机近点到远点进行混合，这其实是一种Ray Marching，不过是在3D纹理的纹理空间进行Ray Marching，一次前进一个像素。当混合当前像素和上一个像素时，需要考虑符合物理的透光率(transmittance), \(\varepsilon\)是一个用于归一化的常量，l是两点之间的距离，c是介质的吸收率（一定程度上可以用雾的密度来表示）。具体的混合的计算和说明可以看EA寒霜引擎的PPT第28、29页。 $$ \tag{Beer-Lambert} transmittance = e^{-\varepsilon l c} $$
最终在绘制物体时，使用物体的世界空间的坐标，转换到3D纹理的坐标，采样3D纹理，使用透光率乘上物体本身的颜色，再加上雾的颜色，就得到了最终的体积雾的效果了。 相关代码和说明 VolumetricFog.cs 用于Global Volume中方便添加体积雾和控制各种参数。值得考虑的是maxTransmittance的值，因为相机远裁剪面会比较远，即使雾并不是很大，在最远处也总是能变成单一的颜色，这个值用来防止这种情况，人为地限制了最大不透光率（但是还是叫maxTransmittance）。fogNear这个参数实际是影响了3D纹理和相机之间的距离，最好还是设置成0，不然时空混合时会有一些瑕疵。...</p></section><footer class=entry-footer>August 23, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用和视锥体对齐的3D纹理来渲染体积雾" href=https://zznewclear13.github.io/posts/create-volumetric-fog-using-view-aligned-3d-texture/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/ViewSpaceNormalFromDepthTexture.jpg alt="View Space Normal From Depth Texture Cover"></figure><header class=entry-header><h2>从深度图中获取视空间的法线</h2></header><section class=entry-content><p>为什么要从深度图重建视空间法线 一个很大的应用情景是在后处理的阶段，或是计算一些屏幕空间的效果（如SSR、SSAO等），只能获取到一张深度贴图，而不是每一个几何体的顶点数据，很多的计算中却又需要用到世界空间的法线或者是视空间的法线，这时我们就需要通过深度图来重建视空间的法线。（诶这段话我是不是写过一遍了）
重建视空间法线的方法 bgolus在他的WorldNormalFromDepthTexture.shader里面很全面的介绍了各种重建视空间法线的方法。其中比较值得注意的是来自Janos Turanszki的根据深度差判断当前像素属于哪个平面的方法，和来自吴彧文的横向和纵向多采样一个点来判断当前像素属于哪个平面的方法，其中吴彧文的方法能够在绝大部分情况下获取到最准确的法线（除了尖角的一个像素）。
除了bgolus介绍的方法之外，我在GameTechDev/XeGTAO中还看到了一种方法。这种方法类似于Janos Turanszki的深度差的方法，不过从深度差中获取的是0-1的边缘值（edgesLRTB，edgesLRTB.x越接近0即代表该像素的左侧越是一条边缘），再使用边缘的两两乘积对四个法线进行插值，最终计算出视空间法线。我个人认为当在两个面相接的地方不需要特别准确的法线值时，这是最好的计算法线的方法。用这个方式计算的法线，在两个面相接的地方，法线会有一种从一个面插值到另一个面的效果（且一定程度上抗锯齿），在两个面远近排布的时候，也能获取到准确的法线。
具体的实现方法 根据需要使用的方法，采样深度图。在采样比较集中的情况下，可以使用GatherRed方法来减少采样的次数。GatherRed可以得到双线性采样时的四个像素的R通道的值并封装到一个float4中，当屏幕左下角是(0, 0)时，这个float4的x分量对应采样点左上角的颜色的R通道的值，y对应右上角，z对应右下角，w对应左下角，可以在HLSL的文档中看到Gather的相关介绍。Compute Shader的话可以使用group shared memory进一步减少采样。 使用深度图和当前的uv值计算出像素的视空间的坐标，这一步尤其需要注意视空间坐标Z分量的正负性的问题。Unity的视空间变换矩阵UNITY_MATRIX_V是摄像机位于视空间(0, 0, 0)，看向视空间Z轴负方向的，右手系的矩阵。即视空间的坐标Z分量往往是一个负值，其法线的Z分量在往往下是正值（即画面看上去应该多为蓝色）。 从深度图中计算视空间坐标的时候，如果Unity版本比较旧，会没有UNITY_MATRIX_I_P这个矩阵，这时可以使用unity_CameraInvProjection来代替，但需要注意DirectX平台UV上下翻转的问题。 当屏幕左下角是(0, 0)时，使用右侧的视空间坐标减去左侧的视空间坐标，使用上侧的视空间坐标减去下侧的视空间坐标。五个采样点（包括位于中心的当前像素）可以获得四个向量，对于右手系的视空间坐标来说，将这四个向量按照水平向量叉乘竖直向量的顺序，就可以获得四个当前像素的法线了。 最后使用前面介绍的获取法线的方法，从这四个法线中获取最为正确的法线。这些方法往往都会使用深度值来进行判断，这里需要注意的是透视变换带来的深度的非线性的问题。对于屏幕上等距分布的三个点ABC，当他们在世界空间中处于同一条直线时，有 $$ 2 \cdot rawDepthB = rawDepthA + rawDepthC \newline \frac 2 {linearDepthB} = \frac 1 {linearDepthA} + \frac 1 {linearDepthC} $$ ReconstructNormalComputeShader.compute 使用GatherRed的方法，可以减少ReconstructNormalAccurate所需要的的采样，但是在屏幕的边缘会有一些瑕疵，把采样的sampler改成sampler_LinearRepeat在一定程度上能够解决这些瑕疵。这样的话ReconstructNormalFast需要两次采样，ReconstructNormalAccurate则需要五次采样。 要注意使用边缘信息对法线进行插值的方法，需要先对法线进行归一化，不然叉乘导致前后平面计算出的向量长度会远大于同一平面的向量长度，影响最终的法线。
#pragma kernel ReconstructNormalFast
#pragma kernel ReconstructNormalAccurate
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
#define FEWER_SAMPLES 0
Texture2D&lt;float> _DepthTexture;
RWTexture2D&lt;float4> _RW_NormalTexture;
SamplerState sampler_LinearClamp;
SamplerState sampler_LinearRepeat;
float4 _TextureSize;
float3 GetViewSpacePosition(float2 uv, float depth)
{
#if UNITY_UV_STARTS_AT_TOP
uv....</p></section><footer class=entry-footer>January 27, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 从深度图中获取视空间的法线" href=https://zznewclear13.github.io/posts/get-view-space-normal-from-depth-texture/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/VertexAnimatedPlant.gif alt="Vertex Animated Plant Cover"></figure><header class=entry-header><h2>使用顶点动画制作随风飘动的植物</h2></header><section class=entry-content><p>动机和想要实现的效果 最直接的动机是看了顽皮狗在Siggraph 2016上的PPT，里面介绍了顽皮狗在神秘海域中是如何让植被随风飘荡的。他们介绍了一种将植被的每一部分的pivot的物体空间坐标写到顶点色里，然后在shader中使用这个坐标进行风的效果的计算的方法。较为震撼在风吹过草原时，植被进行弯曲后，草表面的高光会有一种时空上的起伏感（也就是说神秘海域的植被的法线也会被风影响）。所以我也想要借助写pivot的方法来制作植被受到风吹的效果，通过这个方法计算出正确的风吹之后的植被的法线（同时由于法线贴图的存在，还要计算正确的切线）。
稍微翻了一下网上的资料（也没仔细地去搜索），大部分的就是一个普通的顶点动画，有的是用的sin，有的就直接平移。这就产生了第二个需求，植被在顶点动画中应该保持差不多的长度，不然会发现很明显的拉伸的效果。
当然最好还能投射出正常的影子了，这一步只需要把顶点着色器复制一份到投射影子的pass里就可以了。
这里使用的植被模型是MegaScans上的CORDYLINE模型中的var12这个小模型。
难点和相对应的应对方法 Unity的顶点色限制 稍微测试一下就能发现，Unity的顶点色是UNorm8的格式，也就是说无论你在Maya或是3ds Max里导出的模型的顶点色信息是什么样的，导入到Unity中就会变成只有256精度的UNorm8。顽皮狗使用的是自己的引擎，所以它们能够使用全精度的顶点色，但是由于Unity的引擎限制，我们可以考虑到导出pivot的顶点坐标到模型的UV中。
但是很不幸的是，fbx导入到Unity时，即使UV是float4的类型（也就是16bytes)，在Unity中只会识别UV的前两位。所以只能无奈的将pivot的顶点坐标（float3的数据）储存到两个UV的三个通道里，同时将pivot的层级存到剩下的一个通道里。我不知道顽皮狗具体是怎么计算pivot的层级关系的，他在PPT中写的是无需计算，但我在实际操作中只能一层一层的算（而且只能算两层），也希望知道具体怎么操作的人告知一下方法。
所以接下来要做的是在Maya中把pivot的物体空间坐标和pivot的层级写到对应顶点的某两套UV中，本文是写到第二套和第三套UV中（也就是TEXCOORD1和TEXCOORD2）。于是我恶补了一下maya的python脚本的写法，不过在写数值到UV中时，又遇到了一个小问题。Maya的cmds.polyEditUV这个方法，明明能传入uvSetName这个参数，用于操作对应的UV，但我实际使用时只能写数值到当前的UV中，导致最后写的脚本只能僵硬的操作当前UV，每次切换UV时需要重新修改脚本再运行一次。
最终的脚本是这样的：
VertexPivotWriteTool.py import maya.cmds as cmds targetVertexStr = "Select any vertex to start." vertexColorStr = "Select any vertex to start." pivotPosition = [0.0, 0.0, 0.0] def ui(): if cmds.window("VertexPivotWriteTool", exists = True): cmds.deleteUI("VertexPivotWriteTool") global targetVertexStr global targetVertexField global vertexColorStr global vertexColorField global pivotLayer vertexPivotWindow = cmds.window("VertexPivotWriteTool", widthHeight = [500, 400]) form = cmds.formLayout(numberOfDivisions = 100) pivotLayerLable = cmds.text("Pivot Layer (0 for root pivot)") pivotLayer = cmds....</p></section><footer class=entry-footer>January 6, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用顶点动画制作随风飘动的植物" href=https://zznewclear13.github.io/posts/create-plant-swaying-in-wind-using-vertex-animation/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://zznewclear13.github.io/posts/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://zznewclear13.github.io/>ZZNEWCLEAR13</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>