<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>从视差映射、浮雕映射中获取正确的深度值 | ZZNEWCLEAR13</title><meta name=keywords content="Relaxed Cone Step Mapping,Parallax Occlusion Mapping,Space Transformation"><meta name=description content="同时适配模型本身UV、缩放，和贴图的平铺."><meta name=author content="zznewclear13"><link rel=canonical href=https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/><link crossorigin=anonymous href=/assets/css/stylesheet.min.50ec5873d43aafdb2c832cfa897c60d6e146a48ba3bacc322156221e9661fdc6.css integrity="sha256-UOxYc9Q6r9ssgyz6iXxg1uFGpIujuswyIVYiHpZh/cY=" rel="preload stylesheet" as=style><link rel=preload href=/images/address.png as=image><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://zznewclear13.github.io/favicon.ico><link rel=apple-touch-icon href=https://zznewclear13.github.io/favicon.ico><link rel=mask-icon href=https://zznewclear13.github.io/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-157509723-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="从视差映射、浮雕映射中获取正确的深度值"><meta property="og:description" content="同时适配模型本身UV、缩放，和贴图的平铺."><meta property="og:type" content="article"><meta property="og:url" content="https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/"><meta property="og:image" content="https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/posts/images/CorrectDepth_POM_RCSM.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-16T12:00:00+08:00"><meta property="article:modified_time" content="2024-03-16T12:00:00+08:00"><meta property="og:site_name" content="ZZNEWCLEAR13 - Should I say something cool here?"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/posts/images/CorrectDepth_POM_RCSM.png"><meta name=twitter:title content="从视差映射、浮雕映射中获取正确的深度值"><meta name=twitter:description content="同时适配模型本身UV、缩放，和贴图的平铺."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zznewclear13.github.io/posts/"},{"@type":"ListItem","position":2,"name":"从视差映射、浮雕映射中获取正确的深度值","item":"https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"从视差映射、浮雕映射中获取正确的深度值","name":"从视差映射、浮雕映射中获取正确的深度值","description":"同时适配模型本身UV、缩放，和贴图的平铺.","keywords":["Relaxed Cone Step Mapping","Parallax Occlusion Mapping","Space Transformation"],"articleBody":"POM和RCSM 在我之前的文章在Unity里实现松散圆锥步进Relaxed Cone Step Mapping就已经介绍过了视差映射和松散圆锥步进浮雕映射的计算方法了，但是之前并没有对计算深度值做相应的研究，同时也限制于篇幅的原因就没有再展开了，这篇文章相当于是之前文章的后续。为了简便，后续将这两种计算方法统称为视差映射。\n在视差映射中计算深度值是一个很直接的想法，因为很有可能会有其他物体被放置在视差映射的表面，与之发生穿插，如果不做特殊处理，就会使用模型本身的深度值进行深度比较，导致别的物体不能有正确的被遮挡的效果，削弱了视差映射带来的真实感。网上我找了一圈，并没有找到和计算视差映射的深度值相关的文章，因此我想用这篇文章进行相关的介绍。\nUnity的高清管线（HDRP）的Lit Shader支持计算像素深度偏移，提供了Primitive Length，Primitive Width，和Amplitude三个参数。Amplitude可以用来控制视差映射的强度值，虽然其一个单位和世界空间的一米完全不能直接等同起来，但是值越大视差看上去就越深，可以根据视觉实时调整这个参数。另外两个参数就很奇怪了，居然和模型的大小有关，同一个材质球，用在Quad上这里就要填1，用在Plane上就要填10，哪有这种道理？虚幻引擎则是提供了POM的接口，至于输入和输出完全都由用户控制，这里就不太好直接比较了。\n回顾POM的计算过程 视差映射一般不会直接在世界空间步进，而是会先将世界空间的视线viewWS转换到切线空间viewTS，在切线空间步进。照常理_ParallaxIntensity是用来控制视差映射的深度的，因此会使用这个参数控制z方向步进的距离，但为了方便和高度图中记载的高度进行对比，会先对viewTS的z分量进行归一化，将_ParallaxIntensity在步进时乘到viewTS的xy分量上，之后就是循环比较深度进入下一个循环了。\n但是为什么是切线空间呢？这是因为切线tangent和副切线bitangent代表了贴图UV的xy的正方向，将视线转换到切线空间，其实目的是将视线转到UV空间，或者说是贴图空间（Texture Space，因为其与切线空间的相似性，我们还是用TS来做简写）。这里就出现了最重要的一个问题，Unity中通过GetVertexNormalInputs获得到的世界空间的切线是经过归一化的，丢失了物体自身的缩放，所以我们其实应该先将世界坐标的视线viewWS转换到物体空间viewOS，然后再使用物体空间的tbn矩阵，将viewOS转换到切线空间viewTS。但又如我上面说到的，我们真实的目的是贴图空间，切线空间和贴图空间是存在差异性的。这也就是为什么Unity的HDRP要使用额外的参数Primitive Length和Primitive Width了，这两个参数的目的是通过额外的缩放，将切线空间和贴图空间对应起来。\n这两个参数的意义应当是，贴图空间的xy分量每一个单位在物体空间的长度，这里我们记为uvScale。同时我们可以顺理成章地正式引入_ParallaxIntensity这个参数，它的含义应当是，贴图中颜色为0的点对应的物体空间的深度值。贴图空间转换到物体空间，只需要对xyz三个分量分别乘上uvScale.x，uvScale.y，和_ParallaxIntensity即可。_ParallaxIntensity这个参数我们可以作为材质球的一个输入进行控制，uvScale是一个跟模型相关的参数，我们可以在Geometry Shader中计算而得。\nuvScale的计算 如上面所属，uvScale指代的是贴图空间的xy分量每一个单位在物体空间的长度。对于两个顶点v0和v1，贴图空间的xy分量其实就是这两个顶点uv值的差，物体空间的长度其实就是两个顶点之间的距离，为了对应到贴图空间上，我们需要计算这段距离在切线和副切线上的投影长度，后者除以前者就是我们需要的uvScale了。由于构成三角形的三个顶点可能会存在某两个顶点之间uv的某个分量的变化率为0，导致我们计算uvScale的时候除以零，我们在检测到这个情况的时候使用第三个顶点即可。\n贴图空间变换 在获得了物体空间的切线、副切线和法线之后，为了构成贴图空间的三个基向量，我们需要对这个向量使用uvScale和_ParallaxIntensity进行缩放。这个缩放导致了我们按照以往的float3x3(tangentOS * uvScale.x, bitangentOS * uvScale.y, normalOS * _ParallaxIntensity)构成的矩阵不再是一个正交矩阵，它实际上是贴图空间到物体空间的变换矩阵的转置。因此将物体空间的视线viewOS转换到贴图空间viewTS时，我们要用这个矩阵的转置的逆左乘viewOS，将贴图空间的视线viewTS转换到物体空间viewOS时，我们要用这个矩阵的转置左乘viewTS。\n深度的获取 这个就相对来说比较简单了，我们在贴图空间步进的时候，可以知道我们在贴图空间步进的z方向的深度值len。而由于我们的viewTS会做除以z分量的归一化，我们只需要用归一化前的-viewTS乘上len再除以z分量，就能知道我们在贴图空间中总的步进的向量，将其转换到物体空间再转换到世界空间，和当前点的世界空间的坐标相加后再转换到裁剪空间，其z分量除以w分量就是我们需要的深度值了。\n具体的代码 这里只做了可行性的研究，应该有个方法能够简化计算矩阵的逆这一步操作。在计算世界空间的切线、副切线和法线的时候，可以不进行归一化，这样我们也就不需要先转换到物体空间再转换到贴图空间了。\nPOMShader.shader Shader \"zznewclear13/POMShader\"\r{\rProperties\r{\r[Toggle(OUTPUT_DEPTH)] _OutputDepth (\"Output Depth\", Float) = 1\r_BaseColor(\"Base Color\", Color) = (1, 1, 1, 1)\r_MainTex (\"Texture\", 2D) = \"white\" {}\r_HeightMap(\"Height Map\", 2D) = \"white\" {}\r_NormalMap(\"Normal Map\", 2D) = \"bump\" {}\r_NormalIntensity(\"Normal Intensity\", Range(0, 2)) = 1\r_ParallaxIntensity (\"Parallax Intensity\", Float) = 1\r_ParallaxIteration (\"Parallax Iteration\", Float) = 15\r}\rHLSLINCLUDE\r#include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl\"\r#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\"\r#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\"\r#pragma shader_feature OUTPUT_DEPTH\rsampler2D _MainTex;\rsampler2D _HeightMap;\rsampler2D _NormalMap;\rCBUFFER_START(UnityPerMaterial)\rfloat4 _BaseColor;\rfloat4 _MainTex_ST;\rfloat _NormalIntensity;\rfloat _ParallaxIntensity;\rfloat _ParallaxIteration;\rCBUFFER_END\rstruct a2v\r{\rfloat4 positionOS : POSITION;\rfloat3 normalOS : NORMAL;\rfloat4 tangentOS : TANGENT;\rfloat2 texcoord : TEXCOORD0;\r};\rstruct v2g\r{\rfloat4 positionCS : SV_POSITION;\rfloat3 positionOS : TEXCOORD0;\rfloat3 positionWS : TEXCOORD1;\rfloat4 tangentOS : TEXCOORD2;\rfloat3 bitangentOS : TEXCOORD3;\rfloat3 normalOS : TEXCOORD4;\rfloat2 texcoord : TEXCOORD5;\r};\rstruct g2f\r{\rfloat4 positionCS : SV_POSITION;\rfloat2 uv : TEXCOORD1;\rfloat4 tbnWSPos[3] : TEXCOORD2; // tbnWS, posWS\rfloat4 tbnOSView[3] : TEXCOORD5; // tbnOS, viewWS\rfloat2 uvScale : TEXCOORD8;\r};\rv2g vert(a2v input)\r{\rv2g output = (v2g)0;\rVertexPositionInputs vpi = GetVertexPositionInputs(input.positionOS.xyz);\rVertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);\routput.positionCS = vpi.positionCS;\routput.positionOS = input.positionOS.xyz;\routput.positionWS = vpi.positionWS;\routput.normalOS = input.normalOS;\routput.tangentOS = input.tangentOS;\routput.bitangentOS = cross(input.normalOS, input.tangentOS.xyz) * input.tangentOS.w * GetOddNegativeScale();\routput.texcoord = input.texcoord;\rreturn output;\r}\r[maxvertexcount(3)]\rvoid geom(triangle v2g IN[3], inout TriangleStream tristream)\r{\rfloat3 camWS = GetCameraPositionWS();\rg2f output = (g2f)0;\rfloat3 posDiff01 = IN[1].positionOS - IN[0].positionOS;\rfloat3 posDiff02 = IN[2].positionOS - IN[0].positionOS;\rfloat3 tangentOS0 = IN[0].tangentOS.xyz;\rfloat3 bitangentOS0 = IN[1].bitangentOS;\rfloat2 uvDiff01 = IN[1].texcoord - IN[0].texcoord;\rfloat2 uvDiff02 = IN[2].texcoord - IN[0].texcoord;\rfloat2 uvScale;\rif (uvDiff01.x != 0.0f) uvScale.x = dot(posDiff01, tangentOS0) / uvDiff01.x;\relse uvScale.x = dot(posDiff02, tangentOS0) / uvDiff02.x;\rif (uvDiff01.y != 0.0f) uvScale.y = dot(posDiff01, bitangentOS0) / uvDiff01.y;\relse uvScale.y = dot(posDiff02, bitangentOS0) / uvDiff02.y;\rfor (int i=0; i= 0.0f ? 1.0f : -1.0f);\rfloat len;\rfloat2 uv = parallax((input.uv * _MainTex_ST.xy + _MainTex_ST.zw), viewTS * float3(_MainTex_ST.xy, 1.0f) / z, len);\r#if defined(OUTPUT_DEPTH)\rfloat3 offsetTS = -viewTS * (len / z);\rfloat3 offsetOS = mul(t2wOS, offsetTS);\rfloat3 positionWS = float3(input.tbnWSPos[0].w, input.tbnWSPos[1].w, input.tbnWSPos[2].w);\rfloat3 posWS = positionWS + mul((float3x3)UNITY_MATRIX_M, offsetOS);\rfloat4 posCS = mul(UNITY_MATRIX_VP, float4(posWS, 1.0f));\rdepth = posCS.z / posCS.w;\r#endif\rfloat4 mainTex = tex2D(_MainTex, uv) * _BaseColor;\rfloat3 normalTS = normalize(UnpackNormalScale(tex2D(_NormalMap, uv), _NormalIntensity));\rfloat3 tws = input.tbnWSPos[0].xyz;\rfloat3 bws = input.tbnWSPos[1].xyz;\rfloat3 nws = input.tbnWSPos[2].xyz;\rfloat3 n = normalize(mul(normalTS, float3x3(tws, bws, nws)));\rLight mainLight = GetMainLight();\rfloat ndotl = max(0.0f, dot(n, mainLight.direction));\rfloat3 color = mainTex.rgb * mainLight.color * ndotl;\rfloat alpha = mainTex.a;\rreturn float4(color, alpha);\r}\rENDHLSL\rSubShader\r{\rTags{ \"RenderType\"=\"Opaque\" \"Queue\"=\"Geometry\"}\rCull Back\rPass\r{\rHLSLPROGRAM\r#pragma vertex vert\r#pragma geometry geom\r#pragma fragment frag\rENDHLSL\r}\r}\r}\rRCSMShader.Shader Shader \"zznewclear13/RCSMShader\"\r{\rProperties\r{\r[Toggle(OUTPUT_DEPTH)] _OutputDepth (\"Output Depth\", Float) = 1\r_BaseColor(\"Base Color\", Color) = (1, 1, 1, 1)\r_MainTex (\"Texture\", 2D) = \"white\" {}\r_RCSMTex(\"RCSM Texture\", 2D) = \"white\" {}\r_NormalMap(\"Normal Map\", 2D) = \"bump\" {}\r_NormalIntensity(\"Normal Intensity\", Range(0, 2)) = 1\r_ParallaxIntensity(\"Parallax Intensity\", Float) = 1\r_ParallaxIteration(\"Parallax Iteration\", Float) = 15\r}\rHLSLINCLUDE\r#include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl\"\r#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\"\r#include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\"\r#pragma shader_feature OUTPUT_DEPTH\rsampler2D _MainTex;\rsampler2D _NormalMap;\rsampler2D _RCSMTex;\rCBUFFER_START(UnityPerMaterial)\rfloat4 _BaseColor;\rfloat4 _MainTex_ST;\rfloat _NormalIntensity;\rfloat _ParallaxIntensity;\rfloat _ParallaxIteration;\rCBUFFER_END\rstruct a2v\r{\rfloat4 positionOS : POSITION;\rfloat3 normalOS : NORMAL;\rfloat4 tangentOS : TANGENT;\rfloat2 texcoord : TEXCOORD0;\r};\rstruct v2g\r{\rfloat4 positionCS : SV_POSITION;\rfloat3 positionOS : TEXCOORD0;\rfloat3 positionWS : TEXCOORD1;\rfloat4 tangentOS : TEXCOORD2;\rfloat3 bitangentOS : TEXCOORD3;\rfloat3 normalOS : TEXCOORD4;\rfloat2 texcoord : TEXCOORD5;\r};\rstruct g2f\r{\rfloat4 positionCS : SV_POSITION;\rfloat2 uv : TEXCOORD1;\rfloat4 tbnWSPos[3] : TEXCOORD2; // tbnWS, posWS\rfloat4 tbnOSView[3] : TEXCOORD5; // tbnOS, viewWS\rfloat2 uvScale : TEXCOORD8;\r};\rv2g vert(a2v input)\r{\rv2g output = (v2g)0;\rVertexPositionInputs vpi = GetVertexPositionInputs(input.positionOS.xyz);\rVertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);\routput.positionCS = vpi.positionCS;\routput.positionOS = input.positionOS.xyz;\routput.positionWS = vpi.positionWS;\routput.normalOS = input.normalOS;\routput.tangentOS = input.tangentOS;\routput.bitangentOS = cross(input.normalOS, input.tangentOS.xyz) * input.tangentOS.w * GetOddNegativeScale();\routput.texcoord = input.texcoord;\rreturn output;\r}\r[maxvertexcount(3)]\rvoid geom(triangle v2g IN[3], inout TriangleStream tristream)\r{\rfloat3 camWS = GetCameraPositionWS();\rg2f output = (g2f)0;\rfloat3 posDiff01 = IN[1].positionOS - IN[0].positionOS;\rfloat3 posDiff02 = IN[2].positionOS - IN[0].positionOS;\rfloat3 tangentOS0 = IN[0].tangentOS.xyz;\rfloat3 bitangentOS0 = IN[1].bitangentOS;\rfloat2 uvDiff01 = IN[1].texcoord - IN[0].texcoord;\rfloat2 uvDiff02 = IN[2].texcoord - IN[0].texcoord;\rfloat2 uvScale;\rif (uvDiff01.x != 0.0f) uvScale.x = dot(posDiff01, tangentOS0) / uvDiff01.x;\relse uvScale.x = dot(posDiff02, tangentOS0) / uvDiff02.x;\rif (uvDiff01.y != 0.0f) uvScale.y = dot(posDiff01, bitangentOS0) / uvDiff01.y;\relse uvScale.y = dot(posDiff02, bitangentOS0) / uvDiff02.y;\rfor (int i=0; i= rcsm.x)\r{\rsamplePos -= stepLength * view;\r}\relse if(samplePos.z = 0.0f ? 1.0f : -1.0f);\rfloat len;\rfloat2 uv = parallax((input.uv * _MainTex_ST.xy + _MainTex_ST.zw), viewTS * float3(_MainTex_ST.xy, 1.0f) / z, len);\r#if defined(OUTPUT_DEPTH)\rfloat3 offsetTS = -viewTS * (len / z);\rfloat3 offsetOS = mul(t2wOS, offsetTS);\rfloat3 positionWS = float3(input.tbnWSPos[0].w, input.tbnWSPos[1].w, input.tbnWSPos[2].w);\rfloat3 posWS = positionWS + mul((float3x3)UNITY_MATRIX_M, offsetOS);\rfloat4 posCS = mul(UNITY_MATRIX_VP, float4(posWS, 1.0f));\rdepth = posCS.z / posCS.w;\r#endif\rfloat4 mainTex = tex2D(_MainTex, uv) * _BaseColor;\rfloat3 normalTS = normalize(UnpackNormalScale(tex2D(_NormalMap, uv), _NormalIntensity));\rfloat3 tws = input.tbnWSPos[0].xyz;\rfloat3 bws = input.tbnWSPos[1].xyz;\rfloat3 nws = input.tbnWSPos[2].xyz;\rfloat3 n = normalize(mul(normalTS, float3x3(tws, bws, nws)));\rLight mainLight = GetMainLight();\rfloat ndotl = max(0.0f, dot(n, mainLight.direction));\rfloat3 color = mainTex.rgb * mainLight.color * ndotl;\rfloat alpha = mainTex.a;\rreturn float4(color, alpha);\r}\rENDHLSL\rSubShader\r{\rTags{ \"RenderType\"=\"Opaque\" \"Queue\"=\"Geometry\"}\rCull Back\rPass\r{\rHLSLPROGRAM\r#pragma vertex vert\r#pragma geometry geom\r#pragma fragment frag\rENDHLSL\r}\r}\r}\r最终的效果 最后的效果也就如封面图一样了，左边是RCSM做的，其余的则是普通的POM效果。特地对模型做了缩放，对贴图的平铺进行调整，用来表明这个计算方式的正确性，同样的材质球用在不同的模型上也能够得到正确的深度值。但是像球体这样的uv并不规则的模型，用上述的方法并不能得到完美的深度效果。上面和下面平面使用的贴图来自Quixel的Megascans。\n后记 又迅速地写了一篇文章，计算了视差映射的深度值之后，各种屏幕空间的算法也都能够正常地使用了，很好。话又说回来了我被LearnOpenGL的贴图坑了一波，居然没有意识到上面的法线图和平常使用的法线图是不一样的，我就说怎么看上去有一种违和感。后来我直接在Blender里自己导出了这个Toy Box的法线和深度图，这才感觉一切都正常了。\n","wordCount":"1871","inLanguage":"en","image":"https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/posts/images/CorrectDepth_POM_RCSM.png","datePublished":"2024-03-16T12:00:00+08:00","dateModified":"2024-03-16T12:00:00+08:00","author":{"@type":"Person","name":"zznewclear13"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zznewclear13.github.io/posts/get-correct-depth-from-parallax-occlusion-mapping/"},"publisher":{"@type":"Organization","name":"ZZNEWCLEAR13","logo":{"@type":"ImageObject","url":"https://zznewclear13.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://zznewclear13.github.io/ accesskey=h title="ZZNEWCLEAR13 (Alt + H)"><img src=/apple-touch-icon.png alt=logo aria-label=logo height=35>ZZNEWCLEAR13</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://zznewclear13.github.io/now/ title=进行时><span>进行时</span></a></li><li><a href=https://zznewclear13.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://zznewclear13.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://zznewclear13.github.io/links/ title=友情链接><span>友情链接</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://zznewclear13.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://zznewclear13.github.io/posts/>Posts</a></div><h1 class=post-title>从视差映射、浮雕映射中获取正确的深度值</h1><div class=post-description>同时适配模型本身UV、缩放，和贴图的平铺.</div><div class=post-meta>March 16, 2024&nbsp;·&nbsp;zznewclear13&nbsp;|&nbsp;<a href=https://github.com/zznewclear13/zznewclear13.com/blob/main/content/posts/get-correct-depth-from-parallax-occlusion-mapping.md rel="noopener noreferrer" target=_blank>编辑</a></div></header><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/CorrectDepth_POM_RCSM.png alt="Correct Depth POM & RCSM Cover"><p>Correct Depth POM & RCSM Example</p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>从视差映射、浮雕映射中获取正确的深度值</div></summary><div class=inner><ul><li><a href=#pom%e5%92%8crcsm aria-label=POM和RCSM>POM和RCSM</a></li><li><a href=#%e5%9b%9e%e9%a1%bepom%e7%9a%84%e8%ae%a1%e7%ae%97%e8%bf%87%e7%a8%8b aria-label=回顾POM的计算过程>回顾POM的计算过程</a><ul><li><a href=#uvscale%e7%9a%84%e8%ae%a1%e7%ae%97 aria-label=uvScale的计算>uvScale的计算</a></li><li><a href=#%e8%b4%b4%e5%9b%be%e7%a9%ba%e9%97%b4%e5%8f%98%e6%8d%a2 aria-label=贴图空间变换>贴图空间变换</a></li><li><a href=#%e6%b7%b1%e5%ba%a6%e7%9a%84%e8%8e%b7%e5%8f%96 aria-label=深度的获取>深度的获取</a></li></ul></li><li><a href=#%e5%85%b7%e4%bd%93%e7%9a%84%e4%bb%a3%e7%a0%81 aria-label=具体的代码>具体的代码</a><ul><li><a href=#pomshadershader aria-label=POMShader.shader>POMShader.shader</a></li><li><a href=#rcsmshadershader aria-label=RCSMShader.Shader>RCSMShader.Shader</a></li></ul></li><li><a href=#%e6%9c%80%e7%bb%88%e7%9a%84%e6%95%88%e6%9e%9c aria-label=最终的效果>最终的效果</a></li><li><a href=#%e5%90%8e%e8%ae%b0 aria-label=后记>后记</a></li></ul></div></details></div><div class=post-content><h2 id=pom和rcsm>POM和RCSM<a hidden class=anchor aria-hidden=true href=#pom和rcsm>#</a></h2><p>在我之前的文章<a href=https://zznewclear13.github.io/relaxed-cone-step-mapping-in-unity/>在Unity里实现松散圆锥步进Relaxed Cone Step Mapping</a>就已经介绍过了视差映射和松散圆锥步进浮雕映射的计算方法了，但是之前并没有对计算深度值做相应的研究，同时也限制于篇幅的原因就没有再展开了，这篇文章相当于是之前文章的后续。为了简便，后续将这两种计算方法统称为视差映射。</p><p>在视差映射中计算深度值是一个很直接的想法，因为很有可能会有其他物体被放置在视差映射的表面，与之发生穿插，如果不做特殊处理，就会使用模型本身的深度值进行深度比较，导致别的物体不能有正确的被遮挡的效果，削弱了视差映射带来的真实感。网上我找了一圈，并没有找到和计算视差映射的深度值相关的文章，因此我想用这篇文章进行相关的介绍。</p><p>Unity的高清管线（HDRP）的Lit Shader支持计算像素深度偏移，提供了<code>Primitive Length</code>，<code>Primitive Width</code>，和<code>Amplitude</code>三个参数。<code>Amplitude</code>可以用来控制视差映射的强度值，虽然其一个单位和世界空间的一米完全不能直接等同起来，但是值越大视差看上去就越深，可以根据视觉实时调整这个参数。另外两个参数就很奇怪了，居然和模型的大小有关，同一个材质球，用在Quad上这里就要填1，用在Plane上就要填10，哪有这种道理？虚幻引擎则是提供了POM的接口，至于输入和输出完全都由用户控制，这里就不太好直接比较了。</p><h2 id=回顾pom的计算过程>回顾POM的计算过程<a hidden class=anchor aria-hidden=true href=#回顾pom的计算过程>#</a></h2><p>视差映射一般不会直接在世界空间步进，而是会先将世界空间的视线<code>viewWS</code>转换到切线空间<code>viewTS</code>，在切线空间步进。照常理<code>_ParallaxIntensity</code>是用来控制视差映射的深度的，因此会使用这个参数控制z方向步进的距离，但为了方便和高度图中记载的高度进行对比，会先对<code>viewTS</code>的z分量进行归一化，将<code>_ParallaxIntensity</code>在步进时乘到<code>viewTS</code>的xy分量上，之后就是循环比较深度进入下一个循环了。</p><p>但是为什么是切线空间呢？这是因为切线tangent和副切线bitangent代表了贴图UV的xy的正方向，将视线转换到切线空间，其实目的是将视线转到UV空间，或者说是贴图空间（Texture Space，因为其与切线空间的相似性，我们还是用TS来做简写）。这里就出现了最重要的一个问题，Unity中通过<code>GetVertexNormalInputs</code>获得到的世界空间的切线是经过归一化的，丢失了物体自身的缩放，所以我们其实应该先将世界坐标的视线<code>viewWS</code>转换到物体空间<code>viewOS</code>，然后再使用物体空间的tbn矩阵，将<code>viewOS</code>转换到切线空间<code>viewTS</code>。但又如我上面说到的，我们真实的目的是贴图空间，切线空间和贴图空间是存在差异性的。这也就是为什么Unity的HDRP要使用额外的参数<code>Primitive Length</code>和<code>Primitive Width</code>了，这两个参数的目的是通过额外的缩放，将切线空间和贴图空间对应起来。</p><p>这两个参数的意义应当是，贴图空间的xy分量每一个单位在物体空间的长度，这里我们记为<code>uvScale</code>。同时我们可以顺理成章地正式引入<code>_ParallaxIntensity</code>这个参数，它的含义应当是，贴图中颜色为0的点对应的物体空间的深度值。贴图空间转换到物体空间，只需要对xyz三个分量分别乘上<code>uvScale.x</code>，<code>uvScale.y</code>，和<code>_ParallaxIntensity</code>即可。<code>_ParallaxIntensity</code>这个参数我们可以作为材质球的一个输入进行控制，<code>uvScale</code>是一个跟模型相关的参数，我们可以在Geometry Shader中计算而得。</p><h3 id=uvscale的计算>uvScale的计算<a hidden class=anchor aria-hidden=true href=#uvscale的计算>#</a></h3><p>如上面所属，<code>uvScale</code>指代的是贴图空间的xy分量每一个单位在物体空间的长度。对于两个顶点<code>v0</code>和<code>v1</code>，贴图空间的xy分量其实就是这两个顶点uv值的差，物体空间的长度其实就是两个顶点之间的距离，为了对应到贴图空间上，我们需要计算这段距离在切线和副切线上的投影长度，后者除以前者就是我们需要的<code>uvScale</code>了。由于构成三角形的三个顶点可能会存在某两个顶点之间uv的某个分量的变化率为0，导致我们计算<code>uvScale</code>的时候除以零，我们在检测到这个情况的时候使用第三个顶点即可。</p><h3 id=贴图空间变换>贴图空间变换<a hidden class=anchor aria-hidden=true href=#贴图空间变换>#</a></h3><p>在获得了物体空间的切线、副切线和法线之后，为了构成贴图空间的三个基向量，我们需要对这个向量使用<code>uvScale</code>和<code>_ParallaxIntensity</code>进行缩放。这个缩放导致了我们按照以往的<code>float3x3(tangentOS * uvScale.x, bitangentOS * uvScale.y, normalOS * _ParallaxIntensity)</code>构成的矩阵不再是一个正交矩阵，它实际上是贴图空间到物体空间的变换矩阵的转置。因此将物体空间的视线<code>viewOS</code>转换到贴图空间<code>viewTS</code>时，我们要用这个矩阵的转置的逆左乘<code>viewOS</code>，将贴图空间的视线<code>viewTS</code>转换到物体空间<code>viewOS</code>时，我们要用这个矩阵的转置左乘<code>viewTS</code>。</p><h3 id=深度的获取>深度的获取<a hidden class=anchor aria-hidden=true href=#深度的获取>#</a></h3><p>这个就相对来说比较简单了，我们在贴图空间步进的时候，可以知道我们在贴图空间步进的z方向的深度值<code>len</code>。而由于我们的<code>viewTS</code>会做除以z分量的归一化，我们只需要用归一化前的<code>-viewTS</code>乘上<code>len</code>再除以z分量，就能知道我们在贴图空间中总的步进的向量，将其转换到物体空间再转换到世界空间，和当前点的世界空间的坐标相加后再转换到裁剪空间，其z分量除以w分量就是我们需要的深度值了。</p><h2 id=具体的代码>具体的代码<a hidden class=anchor aria-hidden=true href=#具体的代码>#</a></h2><p>这里只做了可行性的研究，应该有个方法能够简化计算矩阵的逆这一步操作。在计算世界空间的切线、副切线和法线的时候，可以不进行归一化，这样我们也就不需要先转换到物体空间再转换到贴图空间了。</p><h3 id=pomshadershader>POMShader.shader<a hidden class=anchor aria-hidden=true href=#pomshadershader>#</a></h3><pre><code class=language-HLSL data-lang=HLSL>Shader &quot;zznewclear13/POMShader&quot;
{
    Properties
    {
        [Toggle(OUTPUT_DEPTH)] _OutputDepth (&quot;Output Depth&quot;, Float) = 1

        _BaseColor(&quot;Base Color&quot;, Color) = (1, 1, 1, 1)
        _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {}
        _HeightMap(&quot;Height Map&quot;, 2D) = &quot;white&quot; {}
        _NormalMap(&quot;Normal Map&quot;, 2D) = &quot;bump&quot; {}
        _NormalIntensity(&quot;Normal Intensity&quot;, Range(0, 2)) = 1

        _ParallaxIntensity (&quot;Parallax Intensity&quot;, Float) = 1
        _ParallaxIteration (&quot;Parallax Iteration&quot;, Float) = 15
    }

    HLSLINCLUDE
    #include &quot;Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl&quot;
    #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot;
    #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl&quot;

    #pragma shader_feature OUTPUT_DEPTH

    sampler2D _MainTex;
    sampler2D _HeightMap;
    sampler2D _NormalMap;
    CBUFFER_START(UnityPerMaterial)
    float4 _BaseColor;
    float4 _MainTex_ST;
    float _NormalIntensity;
    float _ParallaxIntensity;
    float _ParallaxIteration;
    CBUFFER_END

    struct a2v
    {
        float4 positionOS   : POSITION;
        float3 normalOS     : NORMAL;
        float4 tangentOS    : TANGENT;
        float2 texcoord     : TEXCOORD0;
    };

    struct v2g
    {
        float4 positionCS   : SV_POSITION;
        float3 positionOS   : TEXCOORD0;
        float3 positionWS   : TEXCOORD1;
        float4 tangentOS    : TEXCOORD2;
        float3 bitangentOS  : TEXCOORD3;
        float3 normalOS     : TEXCOORD4;
        float2 texcoord     : TEXCOORD5;
    };
    
    struct g2f
    {
        float4 positionCS   : SV_POSITION;
        float2 uv           : TEXCOORD1;
        float4 tbnWSPos[3]  : TEXCOORD2; // tbnWS, posWS
        float4 tbnOSView[3] : TEXCOORD5; // tbnOS, viewWS
        float2 uvScale      : TEXCOORD8;
    };
    
    v2g vert(a2v input)
    {
        v2g output = (v2g)0;
        VertexPositionInputs vpi = GetVertexPositionInputs(input.positionOS.xyz);
        VertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);
        output.positionCS = vpi.positionCS;
        output.positionOS = input.positionOS.xyz;
        output.positionWS = vpi.positionWS;
        output.normalOS = input.normalOS;
        output.tangentOS = input.tangentOS;
        output.bitangentOS = cross(input.normalOS, input.tangentOS.xyz) * input.tangentOS.w * GetOddNegativeScale();
        output.texcoord = input.texcoord;
        return output;
    }

    [maxvertexcount(3)]
    void geom(triangle v2g IN[3], inout TriangleStream&lt;g2f&gt; tristream)
    {
        float3 camWS = GetCameraPositionWS();
        g2f output = (g2f)0;

        float3 posDiff01 = IN[1].positionOS - IN[0].positionOS;
        float3 posDiff02 = IN[2].positionOS - IN[0].positionOS;
        float3 tangentOS0 = IN[0].tangentOS.xyz;
        float3 bitangentOS0 = IN[1].bitangentOS;
        
        float2 uvDiff01 = IN[1].texcoord - IN[0].texcoord;
        float2 uvDiff02 = IN[2].texcoord - IN[0].texcoord;
        float2 uvScale;
        if (uvDiff01.x != 0.0f) uvScale.x = dot(posDiff01, tangentOS0) / uvDiff01.x;
        else uvScale.x = dot(posDiff02, tangentOS0) / uvDiff02.x;
        if (uvDiff01.y != 0.0f) uvScale.y = dot(posDiff01, bitangentOS0) / uvDiff01.y;
        else uvScale.y = dot(posDiff02, bitangentOS0) / uvDiff02.y;

        for (int i=0; i&lt;3; ++i)
        {
            v2g input = IN[i];

            VertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);
            float3 viewWS = camWS - input.positionWS;
            output.positionCS = input.positionCS;
            output.uv = input.texcoord;
            output.tbnWSPos[0] = float4(vni.tangentWS, input.positionWS.x);
            output.tbnWSPos[1] = float4(vni.bitangentWS, input.positionWS.y);
            output.tbnWSPos[2] = float4(vni.normalWS, input.positionWS.z);
            output.tbnOSView[0] = float4(input.tangentOS.xyz, viewWS.x);
            output.tbnOSView[1] = float4(input.bitangentOS, viewWS.y);
            output.tbnOSView[2] = float4(input.normalOS, viewWS.z);
            output.uvScale = uvScale;
            tristream.Append(output);
        }
        tristream.RestartStrip();
    }

    float sampleHeight(float2 uv)
    {
        return 1.0f - tex2D(_HeightMap, uv).r;
    }

    float2 parallax(float2 uv, float3 view, out float len)
    {
        float numLayers = _ParallaxIteration;
        float layerDepth = 1.0f / numLayers;

        float2 p = view.xy;
        float2 deltaUVs = p / numLayers;

        float texd = sampleHeight(uv);
        float d = 0.0f;
        [unroll(30)]
        for (; d &lt; texd; d += layerDepth)
        {
            uv -= deltaUVs;
            texd = sampleHeight(uv);
        }

        float2 lastUVs = uv + deltaUVs;
        float lastD = d - layerDepth;

        float after = texd - d;
        float before = sampleHeight(lastUVs) - d + layerDepth;
        float w = after / (after - before);
        len = lerp(d, lastD, w);

        return lerp(uv, lastUVs, w);
    }

    // Returns the determinant of a 2x2 matrix.
    float spvDet2x2(float a1, float a2, float b1, float b2)
    {
        return a1 * b2 - b1 * a2;
    }
    // Returns the inverse of a matrix, by using the algorithm of calculating the classical
    // adjoint and dividing by the determinant. The contents of the matrix are changed.
    float3x3 spvInverse(float3x3 m)
    {
        float3x3 adj;	// The adjoint matrix (inverse after dividing by determinant)
        // Create the transpose of the cofactors, as the classical adjoint of the matrix.
        adj[0][0] =  spvDet2x2(m[1][1], m[1][2], m[2][1], m[2][2]);
        adj[0][1] = -spvDet2x2(m[0][1], m[0][2], m[2][1], m[2][2]);
        adj[0][2] =  spvDet2x2(m[0][1], m[0][2], m[1][1], m[1][2]);
        adj[1][0] = -spvDet2x2(m[1][0], m[1][2], m[2][0], m[2][2]);
        adj[1][1] =  spvDet2x2(m[0][0], m[0][2], m[2][0], m[2][2]);
        adj[1][2] = -spvDet2x2(m[0][0], m[0][2], m[1][0], m[1][2]);
        adj[2][0] =  spvDet2x2(m[1][0], m[1][1], m[2][0], m[2][1]);
        adj[2][1] = -spvDet2x2(m[0][0], m[0][1], m[2][0], m[2][1]);
        adj[2][2] =  spvDet2x2(m[0][0], m[0][1], m[1][0], m[1][1]);
        // Calculate the determinant as a combination of the cofactors of the first row.
        float det = (adj[0][0] * m[0][0]) + (adj[0][1] * m[1][0]) + (adj[0][2] * m[2][0]);
        // Divide the classical adjoint matrix by the determinant.
        // If determinant is zero, matrix is not invertable, so leave it unchanged.
        return (det != 0.0f) ? (adj * (1.0f / det)) : m;
    }

    float4 frag(g2f input
#if defined(OUTPUT_DEPTH)
    , out float depth : SV_DEPTH
#endif
    ) : SV_TARGET
    {
        float3 tos = input.tbnOSView[0].xyz * input.uvScale.x;
        float3 bos = input.tbnOSView[1].xyz * input.uvScale.y;
        float3 nos = input.tbnOSView[2].xyz * _ParallaxIntensity;
        float3x3 t2wOS = float3x3(tos.x, bos.x, nos.x,
                                    tos.y, bos.y, nos.y,
                                    tos.z, bos.z, nos.z);

        float3 viewWS = float3(input.tbnOSView[0].w, input.tbnOSView[1].w, input.tbnOSView[2].w);
        float3 viewOS = mul((float3x3)UNITY_MATRIX_I_M, viewWS);
        float3 viewTS = mul(spvInverse(t2wOS), viewOS);

        float z = max(abs(viewTS.z), 1e-5) * (viewTS.z &gt;= 0.0f ? 1.0f : -1.0f);
        float len;
        float2 uv = parallax((input.uv * _MainTex_ST.xy + _MainTex_ST.zw), viewTS * float3(_MainTex_ST.xy, 1.0f) / z, len);
#if defined(OUTPUT_DEPTH)
        float3 offsetTS = -viewTS * (len / z);
        float3 offsetOS = mul(t2wOS, offsetTS);
        float3 positionWS = float3(input.tbnWSPos[0].w, input.tbnWSPos[1].w, input.tbnWSPos[2].w);
        float3 posWS = positionWS + mul((float3x3)UNITY_MATRIX_M, offsetOS);
        float4 posCS = mul(UNITY_MATRIX_VP, float4(posWS, 1.0f));
        depth = posCS.z / posCS.w;
#endif

        float4 mainTex = tex2D(_MainTex, uv) * _BaseColor;
        float3 normalTS = normalize(UnpackNormalScale(tex2D(_NormalMap, uv), _NormalIntensity));
        
        float3 tws = input.tbnWSPos[0].xyz;
        float3 bws = input.tbnWSPos[1].xyz;
        float3 nws = input.tbnWSPos[2].xyz;
        float3 n = normalize(mul(normalTS, float3x3(tws, bws, nws)));
        Light mainLight = GetMainLight();
        float ndotl = max(0.0f, dot(n, mainLight.direction));

        float3 color = mainTex.rgb * mainLight.color * ndotl;
        float alpha = mainTex.a;
        return float4(color, alpha);
    }
            
    ENDHLSL

    SubShader
    {
        Tags{ &quot;RenderType&quot;=&quot;Opaque&quot; &quot;Queue&quot;=&quot;Geometry&quot;}
        Cull Back

        Pass
        {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma geometry geom
            #pragma fragment frag
            ENDHLSL
        }
    }
}
</code></pre><h3 id=rcsmshadershader>RCSMShader.Shader<a hidden class=anchor aria-hidden=true href=#rcsmshadershader>#</a></h3><pre><code class=language-HLSL data-lang=HLSL>Shader &quot;zznewclear13/RCSMShader&quot;
{
    Properties
    {
        [Toggle(OUTPUT_DEPTH)] _OutputDepth (&quot;Output Depth&quot;, Float) = 1

        _BaseColor(&quot;Base Color&quot;, Color) = (1, 1, 1, 1)
        _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {}
        _RCSMTex(&quot;RCSM Texture&quot;, 2D) = &quot;white&quot; {}
        _NormalMap(&quot;Normal Map&quot;, 2D) = &quot;bump&quot; {}
        _NormalIntensity(&quot;Normal Intensity&quot;, Range(0, 2)) = 1

        _ParallaxIntensity(&quot;Parallax Intensity&quot;, Float) = 1
        _ParallaxIteration(&quot;Parallax Iteration&quot;, Float) = 15
    }

    HLSLINCLUDE
    #include &quot;Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl&quot;
    #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl&quot;
    #include &quot;Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl&quot;

    #pragma shader_feature OUTPUT_DEPTH

    sampler2D _MainTex;
    sampler2D _NormalMap;
    sampler2D _RCSMTex;
    CBUFFER_START(UnityPerMaterial)
    float4 _BaseColor;
    float4 _MainTex_ST;
    float _NormalIntensity;
    float _ParallaxIntensity;
    float _ParallaxIteration;
    CBUFFER_END

    struct a2v
    {
        float4 positionOS   : POSITION;
        float3 normalOS     : NORMAL;
        float4 tangentOS    : TANGENT;
        float2 texcoord     : TEXCOORD0;
    };

    struct v2g
    {
        float4 positionCS   : SV_POSITION;
        float3 positionOS   : TEXCOORD0;
        float3 positionWS   : TEXCOORD1;
        float4 tangentOS    : TEXCOORD2;
        float3 bitangentOS  : TEXCOORD3;
        float3 normalOS     : TEXCOORD4;
        float2 texcoord     : TEXCOORD5;
    };
    
    struct g2f
    {
        float4 positionCS   : SV_POSITION;
        float2 uv           : TEXCOORD1;
        float4 tbnWSPos[3]  : TEXCOORD2; // tbnWS, posWS
        float4 tbnOSView[3] : TEXCOORD5; // tbnOS, viewWS
        float2 uvScale      : TEXCOORD8;
    };
    
    v2g vert(a2v input)
    {
        v2g output = (v2g)0;
        VertexPositionInputs vpi = GetVertexPositionInputs(input.positionOS.xyz);
        VertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);
        output.positionCS = vpi.positionCS;
        output.positionOS = input.positionOS.xyz;
        output.positionWS = vpi.positionWS;
        output.normalOS = input.normalOS;
        output.tangentOS = input.tangentOS;
        output.bitangentOS = cross(input.normalOS, input.tangentOS.xyz) * input.tangentOS.w * GetOddNegativeScale();
        output.texcoord = input.texcoord;
        return output;
    }

    [maxvertexcount(3)]
    void geom(triangle v2g IN[3], inout TriangleStream&lt;g2f&gt; tristream)
    {
        float3 camWS = GetCameraPositionWS();
        g2f output = (g2f)0;

        float3 posDiff01 = IN[1].positionOS - IN[0].positionOS;
        float3 posDiff02 = IN[2].positionOS - IN[0].positionOS;
        float3 tangentOS0 = IN[0].tangentOS.xyz;
        float3 bitangentOS0 = IN[1].bitangentOS;
        
        float2 uvDiff01 = IN[1].texcoord - IN[0].texcoord;
        float2 uvDiff02 = IN[2].texcoord - IN[0].texcoord;
        float2 uvScale;
        if (uvDiff01.x != 0.0f) uvScale.x = dot(posDiff01, tangentOS0) / uvDiff01.x;
        else uvScale.x = dot(posDiff02, tangentOS0) / uvDiff02.x;
        if (uvDiff01.y != 0.0f) uvScale.y = dot(posDiff01, bitangentOS0) / uvDiff01.y;
        else uvScale.y = dot(posDiff02, bitangentOS0) / uvDiff02.y;

        for (int i=0; i&lt;3; ++i)
        {
            v2g input = IN[i];

            VertexNormalInputs vni = GetVertexNormalInputs(input.normalOS, input.tangentOS);
            float3 viewWS = camWS - input.positionWS;
            output.positionCS = input.positionCS;
            output.uv = input.texcoord;
            output.tbnWSPos[0] = float4(vni.tangentWS, input.positionWS.x);
            output.tbnWSPos[1] = float4(vni.bitangentWS, input.positionWS.y);
            output.tbnWSPos[2] = float4(vni.normalWS, input.positionWS.z);
            output.tbnOSView[0] = float4(input.tangentOS.xyz, viewWS.x);
            output.tbnOSView[1] = float4(input.bitangentOS, viewWS.y);
            output.tbnOSView[2] = float4(input.normalOS, viewWS.z);
            output.uvScale = uvScale;
            tristream.Append(output);
        }
        tristream.RestartStrip();
    }

    float2 sampleRCSM(float2 uv)
    {
        float2 rcsm = tex2D(_RCSMTex, uv).xy;
        return float2(1.0f - rcsm.x, rcsm.y);
    }

    float getStepLength(float rayRatio, float coneRatio, float rayHeight, float sampleHeight)
    {
        float totalRatio = rayRatio / coneRatio + 1.0f;
        return (sampleHeight - rayHeight) / totalRatio;
    }

    float2 parallax(float2 uv, float3 view, out float len)
    {
        view.xy = -view.xy * _ParallaxIntensity;
        float3 samplePos = float3(uv, 0.0f);
        float2 rcsm = sampleRCSM(samplePos.xy);
        float rayRatio = length(view.xy);
        float coneRatio = rcsm.y;
        float rayHeight = samplePos.z;
        float sampleHeight = rcsm.x;

        float stepLength = getStepLength(rayRatio, coneRatio, rayHeight, sampleHeight);  
        [unroll(30)]
        for (int i = 0; i &lt; _ParallaxIteration; ++i)
        {
            samplePos += stepLength * view;
            rcsm = sampleRCSM(samplePos.xy);
            coneRatio = rcsm.y;
            rayHeight = samplePos.z;
            sampleHeight = rcsm.x;
            if (sampleHeight &lt;= rayHeight) break;
        
            stepLength = getStepLength(rayRatio, coneRatio, rayHeight, sampleHeight);
        }

        stepLength *= 0.5f;
        samplePos -= stepLength * view;

        [unroll]
        for (int j = 0; j &lt; 5; ++j)
        {
            rcsm = sampleRCSM(samplePos.xy);
            stepLength *= 0.5f;
            if (samplePos.z &gt;= rcsm.x)
            {
                samplePos -= stepLength * view;
            }
            else if(samplePos.z &lt; rcsm.x)
            {
                samplePos += stepLength * view;
            }
        }

        len = samplePos.z;
        return samplePos.xy;
    }

    // Returns the determinant of a 2x2 matrix.
    float spvDet2x2(float a1, float a2, float b1, float b2)
    {
        return a1 * b2 - b1 * a2;
    }
    // Returns the inverse of a matrix, by using the algorithm of calculating the classical
    // adjoint and dividing by the determinant. The contents of the matrix are changed.
    float3x3 spvInverse(float3x3 m)
    {
        float3x3 adj;	// The adjoint matrix (inverse after dividing by determinant)
        // Create the transpose of the cofactors, as the classical adjoint of the matrix.
        adj[0][0] =  spvDet2x2(m[1][1], m[1][2], m[2][1], m[2][2]);
        adj[0][1] = -spvDet2x2(m[0][1], m[0][2], m[2][1], m[2][2]);
        adj[0][2] =  spvDet2x2(m[0][1], m[0][2], m[1][1], m[1][2]);
        adj[1][0] = -spvDet2x2(m[1][0], m[1][2], m[2][0], m[2][2]);
        adj[1][1] =  spvDet2x2(m[0][0], m[0][2], m[2][0], m[2][2]);
        adj[1][2] = -spvDet2x2(m[0][0], m[0][2], m[1][0], m[1][2]);
        adj[2][0] =  spvDet2x2(m[1][0], m[1][1], m[2][0], m[2][1]);
        adj[2][1] = -spvDet2x2(m[0][0], m[0][1], m[2][0], m[2][1]);
        adj[2][2] =  spvDet2x2(m[0][0], m[0][1], m[1][0], m[1][1]);
        // Calculate the determinant as a combination of the cofactors of the first row.
        float det = (adj[0][0] * m[0][0]) + (adj[0][1] * m[1][0]) + (adj[0][2] * m[2][0]);
        // Divide the classical adjoint matrix by the determinant.
        // If determinant is zero, matrix is not invertable, so leave it unchanged.
        return (det != 0.0f) ? (adj * (1.0f / det)) : m;
    }

    float4 frag(g2f input
#if defined(OUTPUT_DEPTH)
    , out float depth : SV_DEPTH
#endif
    ) : SV_TARGET
    {
        float3 tos = input.tbnOSView[0].xyz * input.uvScale.x;
        float3 bos = input.tbnOSView[1].xyz * input.uvScale.y;
        float3 nos = input.tbnOSView[2].xyz * _ParallaxIntensity;
        float3x3 t2wOS = float3x3(tos.x, bos.x, nos.x,
                                    tos.y, bos.y, nos.y,
                                    tos.z, bos.z, nos.z);

        float3 viewWS = float3(input.tbnOSView[0].w, input.tbnOSView[1].w, input.tbnOSView[2].w);
        float3 viewOS = mul((float3x3)UNITY_MATRIX_I_M, viewWS);
        float3 viewTS = mul(spvInverse(t2wOS), viewOS);

        float z = max(abs(viewTS.z), 1e-5) * (viewTS.z &gt;= 0.0f ? 1.0f : -1.0f);
        float len;
        float2 uv = parallax((input.uv * _MainTex_ST.xy + _MainTex_ST.zw), viewTS * float3(_MainTex_ST.xy, 1.0f) / z, len);
#if defined(OUTPUT_DEPTH)
        float3 offsetTS = -viewTS * (len / z);
        float3 offsetOS = mul(t2wOS, offsetTS);
        float3 positionWS = float3(input.tbnWSPos[0].w, input.tbnWSPos[1].w, input.tbnWSPos[2].w);
        float3 posWS = positionWS + mul((float3x3)UNITY_MATRIX_M, offsetOS);
        float4 posCS = mul(UNITY_MATRIX_VP, float4(posWS, 1.0f));
        depth = posCS.z / posCS.w;
#endif

        float4 mainTex = tex2D(_MainTex, uv) * _BaseColor;
        float3 normalTS = normalize(UnpackNormalScale(tex2D(_NormalMap, uv), _NormalIntensity));
        
        float3 tws = input.tbnWSPos[0].xyz;
        float3 bws = input.tbnWSPos[1].xyz;
        float3 nws = input.tbnWSPos[2].xyz;
        float3 n = normalize(mul(normalTS, float3x3(tws, bws, nws)));
        Light mainLight = GetMainLight();
        float ndotl = max(0.0f, dot(n, mainLight.direction));

        float3 color = mainTex.rgb * mainLight.color * ndotl;
        float alpha = mainTex.a;
        return float4(color, alpha);
    }
            
    ENDHLSL

    SubShader
    {
        Tags{ &quot;RenderType&quot;=&quot;Opaque&quot; &quot;Queue&quot;=&quot;Geometry&quot;}
        Cull Back

        Pass
        {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma geometry geom
            #pragma fragment frag
            ENDHLSL
        }
    }
}
</code></pre><h2 id=最终的效果>最终的效果<a hidden class=anchor aria-hidden=true href=#最终的效果>#</a></h2><p>最后的效果也就如封面图一样了，左边是RCSM做的，其余的则是普通的POM效果。特地对模型做了缩放，对贴图的平铺进行调整，用来表明这个计算方式的正确性，同样的材质球用在不同的模型上也能够得到正确的深度值。但是像球体这样的uv并不规则的模型，用上述的方法并不能得到完美的深度效果。上面和下面平面使用的贴图来自Quixel的Megascans。</p><p><img loading=lazy src=../images/CorrectDepth_POM_RCSM.png#center alt="Correct Depth POM &amp;amp; RCSM"></p><h2 id=后记>后记<a hidden class=anchor aria-hidden=true href=#后记>#</a></h2><p>又迅速地写了一篇文章，计算了视差映射的深度值之后，各种屏幕空间的算法也都能够正常地使用了，很好。话又说回来了我被LearnOpenGL的贴图坑了一波，居然没有意识到上面的法线图和平常使用的法线图是不一样的，我就说怎么看上去有一种违和感。后来我直接在Blender里自己导出了这个Toy Box的<a href=../images/Toy_Box_Normal.jpg>法线</a>和<a href=../images/Toy_Box_Height.jpg>深度图</a>，这才感觉一切都正常了。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://zznewclear13.github.io/tags/relaxed-cone-step-mapping/>Relaxed Cone Step Mapping</a></li><li><a href=https://zznewclear13.github.io/tags/parallax-occlusion-mapping/>Parallax Occlusion Mapping</a></li><li><a href=https://zznewclear13.github.io/tags/space-transformation/>Space Transformation</a></li></ul><nav class=paginav><a class=next href=https://zznewclear13.github.io/posts/screen-space-reflection-en/><span class=title>Next Page »</span><br><span>Screen Space Reflection</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://zznewclear13.github.io/>ZZNEWCLEAR13</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script><script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script></body></html>