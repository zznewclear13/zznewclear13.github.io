<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | ZZNEWCLEAR13</title><meta name=keywords content><meta name=description content="这里是zznewclear13.com"><meta name=author content="zznewclear13"><link rel=canonical href=https://zznewclear13.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.min.271a60922b24f96a1ee45097f47002c4807a7a7c107386422099ac8c8af51f93.css integrity="sha256-Jxpgkisk+Woe5FCX9HACxIB6enwQc4ZCIJmsjIr1H5M=" rel="preload stylesheet" as=style><link rel=preload href=/images/address.png as=image><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://zznewclear13.github.io/favicon.ico><link rel=apple-touch-icon href=https://zznewclear13.github.io/favicon.ico><link rel=mask-icon href=https://zznewclear13.github.io/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><link rel=alternate type=application/rss+xml href=https://zznewclear13.github.io/posts/index.xml><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-157509723-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Posts"><meta property="og:description" content="这里是zznewclear13.com"><meta property="og:type" content="website"><meta property="og:url" content="https://zznewclear13.github.io/posts/"><meta property="og:image" content="https://zznewclear13.github.io/images/address.png"><meta property="og:site_name" content="ZZNEWCLEAR13 - Should I say something cool here?"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zznewclear13.github.io/images/address.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="这里是zznewclear13.com"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zznewclear13.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://zznewclear13.github.io/ accesskey=h title="ZZNEWCLEAR13 (Alt + H)"><img src=/apple-touch-icon.png alt=logo aria-label=logo height=35>ZZNEWCLEAR13</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://zznewclear13.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://zznewclear13.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://zznewclear13.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/GaussianBlur.jpg alt="Gaussian Blur Cover"></figure><header class=entry-header><h2>使用Group Shared Memory加速高斯模糊</h2></header><section class=entry-content><p>为什么要用Compute Shader来做高斯模糊 在之前的博客中我说Compute Shader的优势就是快，因为GPU的并行运算比CPU强大很多。但是相比于同样运行在GPU上的Fragment Shader之类，Compute Shader是不是就毫无优势了呢？答案是否定的，在DX11的文档中我们可以看到Thread Group Shared Memory这么一个概念，Compute Shader的Thread Group中的每一个Thread，都可以极快速的访问到对应的Group Shared Memory中的数据，这个效率比采样一张贴图来的高。因此在进行高斯模糊这样的需要大量贴图采样的计算时，先将贴图数据缓存到Group Shared Memory中，再多次访问Group Shared Memory，这样运行的效率会高得多。
相关的一些参考可以在英伟达的PPT里找到。
Compute Shader进行高斯模糊的具体操作 这里暂时不使用半分辨率的优化方法，目的是把SrcIden对应的RenderTexture经过高斯模糊储存到DestIden中，这时我们需要一张临时的相同大小的RenderTextureBlurIden。 确定需要的最大的高斯模糊的像素宽度MAX_RADIUS，越大的高斯模糊宽度，需要越大的Group Shared Memory，而Group Shared Memory的大小是有上限的（cs_5.0是32768 bytes）。当然也没有必要在全分辨率的情况下做特别大的高斯模糊就是了。这里我设置最大的高斯模糊像素数是32，即高斯模糊当前像素点和最远采样点之间的距离不能超过32（双线性采样的话还要缩小一个像素）。 高斯模糊往往使用水平和竖直两个高斯核心进行模糊，对应的需要两个Compute Shader Kernel（也可以写成一个，不过思考起来有点绕），我们这里设置两个Kernel，对应水平和竖直两个pass。水平Kernel使用[numthreads(64, 1, 1)]，最高可以是1024，竖直Kernel则使用[numthreads(1, 64, 1)]。 由于高斯模糊中会采样像素点的左右（上下）两侧的像素，Group Shared Memory需要在GroupThreads的基础上向两侧扩大最大高斯模糊像素数MAX_RADIUS，用于保存额外的像素数据。这时我们需要的Group Shared Memory的大小是numthreads + 2 * MAX_RADIUS个，在本文章中是64 + 2 * 32个float3的数据。 GaussianBlur.cs 这里略去Unity SRP的设置pass的操作，仅展示高斯模糊相关的操作。当blurRadius过大时，就能看到明显的多重采样的痕迹了。
private void DoGaussianBlurHorizontal(CommandBuffer cmd, RenderTargetIdentifier srcid, RenderTargetIdentifier dstid, ComputeShader computeShader, float blurRadius) { int gaussianBlurKernel = computeShader.FindKernel("GaussianBlurHorizontalMain"); computeShader.GetKernelThreadGroupSizes(gaussianBlurKernel, out uint x, out uint y, out uint z); cmd....</p></section><footer class=entry-footer>August 19, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用Group Shared Memory加速高斯模糊" href=https://zznewclear13.github.io/posts/accelerate-gaussian-blur-using-group-shared-memory/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/TemporalAntiAliasing.jpg alt="Temporal Anti-Aliasing Cover"></figure><header class=entry-header><h2>在Unity SRP中实现TAA效果</h2></header><section class=entry-content><p>TAA的原理 首先是要了解画面上的锯齿是如何产生的。锯齿发生在光栅化的阶段，光栅化的时候会丢失掉小于一个像素宽的细节，也就导致了锯齿的产生。
从字面上来看，TAA (Temporal Anti-Aliasing)的抗锯齿效果来源于Temporal一词，是一种时间上的抗锯齿。TAA会结合当前渲染的画面和之前渲染的画面，通过这两个画面之间的融合，达成抗锯齿的效果。基本思想是在光栅化的时候对画面进行抖动，让亚像素的细节在不同帧渲染到不同的像素上，最后再对这些像素按时间的权重来混合，就能达到抗锯齿的效果。
Temporal Reprojection Anti-Aliasing Temporal Reprojection Anti-Aliasing是由PlayDead在他们的游戏Inside中使用的一种TAA的方法，他们在GDC2016的演示中分享了这个方法。相较于普通的TAA来说，Temporal Reprojection Anti-Aliasing中使用了Velocity Buffer中的屏幕像素的速度信息和Depth Buffer中对应的屏幕像素的世界坐标信息，这样当物体移动或者相机移动的时候，在做到抗锯齿的同时也减少了TAA带来的拖影效果，同时也把TAA和运动模糊相结合达到更理想的抗锯齿的效果。
PlayDead提供了对应的源代码。本博客中TAA在SRP中的实现也参考了sienaiwun的TAA代码。
在Unity SRP中实现TAA的操作 我们通过RendererFeature的方式在渲染管线中加入TAA。在ForwardRendererData中加入RendererFeature后，往Global Volume中添加Temporal Anti-Aliasing以在场景中启用TAA效果。启用TAA效果后，会现在渲染不透明物体之前调用一个Jitter Pass对相机的栅格化阶段进行抖动；在渲染TAA Pass时（在Bloom等跟物体渲染相关的后处理效果之后，在Chromatic Aberration等跟屏幕空间位置相关的后处理效果之前）根据抖动值还原出正常的不抖动的画面，并和AccumTexture进行混合，获得最终的渲染画面。因此我们需要TAARendererFeature、TAAJitterPass、TAARenderPass这三个脚本来处理渲染管线，TemporalAntiAliasing这个脚本来处理Volume，TAAShader这个Shader文件来进行TAA的混合操作。 对栅格化阶段进行抖动，也就相当于是修改了相机的透视变换矩阵的第一第二行的第三位的值，抖动值最好和TexelSize相结合，这样在TAA反向抖动还原正常值的时候，在shader中会比较好写。抖动值和TAA的反向抖动是正比关系，因此可以不需要特别纠结于计算，在shader中传入一个debug值再和抖动值相乘用作反向抖动，观察最后的画面是否存在抖动，就能很好的判断出这两个值的比例了。抖动的方式有很多，纯随机的抖动也可以选择，不过稍不如使用均匀分布的随机抖动的效果好，这里使用Inside中的方式即利用Halton数列进行抖动。 为了让相机移动时也能有较好的抗锯齿效果且削弱拖影现象，Temporal Reprojection Anti-Aliasing需要采样当前的深度贴图，还原出物体的世界空间的坐标，再计算出这个世界空间在AccumTexture中的UV值(Reprojection)，使用这个UV值采样AccumTexture再和当前渲染画面进行融合。 因为Velocity Buffer比较麻烦，这里暂且忽略掉物体移动对TAA带来的影响。 在ScriptableRenderPass中使用cmd.GetTemporaryRT()获得的Render Texture，在当帧过后就会被回收，因此AccumTexture需要使用RenderTexture.GetTemporary()来获取。这里我把AccumTexture放在TemporalAntiAliasing.cs中，方便使用。 TemporalAntiAliasing.cs 除了普通的Volume的设置之外，还需要提供Render Texture的接口。lastFrame的x值和y值分别对应最后渲染画面中对AccumTexture进行线性插值的最小和最大系数。
using System; namespace UnityEngine.Rendering.Universal { [Serializable, VolumeComponentMenu("Post-processing/Temporal Anti-Aliasing")] public class TemporalAntiAliasing : VolumeComponent, IPostProcessComponent { public BoolParameter isEnabled = new BoolParameter(false); public NoInterpFloatRangeParameter lastFrame = new NoInterpFloatRangeParameter(new Vector2(0.2f, 0.8f), 0f, 1f); public Vector2Parameter jitterIntensity = new Vector2Parameter(Vector2....</p></section><footer class=entry-footer>July 15, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 在Unity SRP中实现TAA效果" href=https://zznewclear13.github.io/posts/temporal-reprojection-anti-aliasing/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/GPUSkinning.jpg alt="GPU Skinning Cover"></figure><header class=entry-header><h2>支持Animator Controller的实时GPU蒙皮</h2></header><section class=entry-content><p>为什么要用GPU来进行蒙皮 对于一个SkinnedMeshRenderer，在做蒙皮的时候，对于每一个顶点，会先计算出这个顶点对应的四根骨骼的从骨骼空间到物体空间的矩阵\(M_{bone\_localtoobject}\)，然后使用\(M_{bone\_localtoobject} * M_{bone\_bindpose} * Vertex_{objectspace}\)得到经过骨骼平移旋转缩放后的四个带权重的顶点数据位置和切线，对于法线则是使用上面矩阵的逆矩阵的转置。然后对获得的位置、法线和切线，用权重计算得到经过骨骼平移旋转缩放后的实际的顶点信息。在通常的渲染过程中，上述操作是在CPU中进行的，最后把顶点数据传递给GPU中进行渲染。在顶点数较多且主要是矩阵运算的情况下，CPU进行蒙皮的效率就不如高并行的GPU了，因此会考虑到在GPU中进行蒙皮处理。
GPU蒙皮的一些想法 从上面可以看到，要从CPU中传给GPU的数据有以下几种：一是\(M_{bone\_localtoobject} * M_{bone\_bindpose}\)这样骨骼数个float4x4的矩阵，但是由于其最后一行是(0, 0, 0, 1)，在传递时可以简化成骨骼数个float3x4矩阵，这些矩阵每一帧都要传递一次；二是每个顶点对应的骨骼编号和骨骼的权重，骨骼编号用来查询骨骼矩阵中对应的矩阵，是一个整型的数据，骨骼权重是一个[0, 1]的小数，可以用\(BoneIndex + BoneWeight * 0.5\)的方式，把编号和权重结合成一个float的数据，这样每个顶点的骨骼编号和权重数据是一个float4的数据，可以保存在UV中，也可以用数组的方式传递给GPU，这些顶点数个float4的数据，只需要传递一次就可以了；再有就是模型本身的顶点位置、法线和切线，这些引擎会自动为我们传递给GPU。
在实际操作中，网上通常找到的方案是把动画保存在一张贴图或者是一个自定义的数据结构中，这里可以直接保存顶点数据，甚至不需要在GPU中做蒙皮的操作，但是随着顶点数增加会占用大量的空间；或者是保存骨骼的变换矩阵，在GPU中进行蒙皮，相对来说储存空间会小很多。然而我认为这两种都不是很好的做GPU skinning的方法，将动画信息保存到贴图或者数据结构中，会很大程度上失去Animator Controller的功能，如两个动作之间的插值、触发事件等，对于动画来说甚至是得不偿失的一种效果。因此，我希望能够保留Animator Controller的特性，实时的把骨骼数据传送给GPU，在GPU中进行蒙皮操作。
GPU蒙皮的操作 我的想法是，先离线从SkinnedMeshRenderer中获得骨骼的ID和权重，然后实时的从Animator Controller对应的骨骼中获取每根骨骼的骨骼矩阵，再统一传给一个普通的MeshRenderer，在GPU中进行蒙皮的操作。这中间有一个小坑，Unity同一个模型的SkinnedMeshRenderer和MeshRenderer，他们虽然都能获取到boneweight和bindpose，但是SkinnedMeshRenderer和MeshRnederer的骨骼的顺序有时候会有一些差异，因此最好的办法是，抛弃这两者的骨骼顺序，用Hierarchy中的骨骼顺序来确定我们传给GPU的boneindex，boneweight和bonematrix是一致的。
这里使用的模型及动作是mixamo的hip hop dancing资源。
BoneMatchInfo.cs 这个脚本的作用是，在离线时把一个GameObjectRoot下的所有SkinnedMeshRenderer和Hierarchy中的骨骼的信息结合起来，保存成一个Asset，用于实时的GPU Skinning。这个Asset包含两部分的信息，一个是BoneMatchNode用于记录Hierarchy骨骼列表中骨骼的名称和其bindpose，另一个是BindIndex用于记录所有SkinnedMeshRenderer的骨骼在Hierarchy骨骼列表中的顺序。
using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEditor; using System; using System.IO; namespace GPUSkinning { [System.Serializable] public class BoneMatchNode { //[HideInInspector] public string boneName; //在查找位于所有Transfom的位置时，设置并使用boneIndex public int boneIndex = 0; public Matrix4x4 bindPose; public BoneMatchNode(string _boneName) { boneName = _boneName; bindPose = Matrix4x4....</p></section><footer class=entry-footer>July 11, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 支持Animator Controller的实时GPU蒙皮" href=https://zznewclear13.github.io/posts/unity-gpu-skinning-with-animator-controller/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/WorldSpaceFromDepthTexture.png alt="World Space From Depth Texture Cover"></figure><header class=entry-header><h2>从深度图中获取世界空间的坐标</h2></header><section class=entry-content><p>为什么要从深度图重建世界坐标 一个很大的应用情景是在后处理的阶段，或是计算一些屏幕空间的效果（如SSR、SSAO等），只能获取到一张深度贴图，而不是每一个几何体的顶点数据，很多的计算中却又需要用到世界坐标或者是视空间的坐标，这时我们就需要通过深度图来重建世界空间的坐标。
重建世界坐标的流程 首先要获取屏幕空间的UV，这里记为positionSS，范围是(0, 1)(0, 1)。 使用UV采样深度贴图，获取到当前的深度值。 使用UV和深度值，得到标准化设备坐标，这里记为positionNDC。 使用裁剪空间到视空间的变换矩阵乘以positionNDC，除以W分量，得到视空间坐标，这里记为positionVS。 使用视空间到世界空间的变换矩阵乘以positionVS，得到世界空间坐标，这里记为positionWS。 这里使用DepthToPositionShader.shader，假装是屏幕后处理的shader，来演示一下重建世界坐标的流程，这样比直接写屏幕后处理的shader能够更好的去了解Unity的空间变换的方式。
这个shader有以下几个需要注意的点：
为了使用_CameraDepthTexture这张深度贴图，需要在srp的设置中开启Depth Texture这个选项。这样子在渲染的时候会在DepthPrePass用shader中的Depth Only这个pass去先渲染出深度贴图。我们就能够在渲染物体的时候直接拿到包含当前物体的深度贴图了。 顶点着色器和片元着色器中的SV_POSITION并不完全相同。对于顶点着色器来说，SV_POSITION就是上一章讲到的\((\frac X {\tan {\frac {fovy} 2} \cdot \frac y x }, - \frac Y {\tan {\frac {fovy} 2}}, \frac {Zn} {f - n} + \frac {fn} {f - n}, Z)\)；但是在片元着色器中，SV_POSITION的XY分量会乘上屏幕的宽高。屏幕的宽高信息保存在_ScreenParams这个内置的变量中，它的前两位是屏幕的宽高像素数，后两位是宽高的像素数的倒数加一。 要针对DX11和OpenGL不同的透视变换矩阵来调整UV的Y分量的数值，也就是要注意UNITY_UV_STARTS_AT_TOP这个宏的使用。出现获得的坐标跟随着摄像机的移动发生奇怪的倾斜的时候，往往都是忘记对Y分量的平台差异进行处理。 最后得到的视空间和世界空间的坐标值，要记得除以这个坐标值的W分量，相当于是做了一次归一化，才能得到正确的坐标。 DepthToPositionShader.shader Shader "zznewclear13/DepthToPositionShader"
{
Properties
{
[Toggle(REQUIRE_POSITION_VS)] _Require_Position_VS("Require Position VS", float) = 0
}
HLSLINCLUDE
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/core.hlsl"
#pragma multi_compile _ REQUIRE_POSITION_VS
sampler2D _CameraDepthTexture;
struct Attributes
{
float4 positionOS : POSITION;
float2 texcoord : TEXCOORD0;
};
struct Varyings
{
float4 positionCS : SV_POSITION;
float2 texcoord : TEXCOORD0;
};
Varyings Vert(Attributes input)
{
Varyings output = (Varyings)0;
VertexPositionInputs vertexPositionInputs = GetVertexPositionInputs(input....</p></section><footer class=entry-footer>July 3, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 从深度图中获取世界空间的坐标" href=https://zznewclear13.github.io/posts/get-world-space-position-from-depth-texture/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/OpenGLViewingFrustum.png alt="Space Transformation Cover"></figure><header class=entry-header><h2>Unity空间变换总览</h2></header><section class=entry-content><p>Unity中的空间变换 将一个物体渲染到我们的屏幕上，需要经过一系列的坐标变换，这些坐标变换是在shader中使用矩阵进行计算的。变换的顺序如下，从物体空间(Object Space)到世界空间(World Space)，从世界空间到视空间(View pace)，从相机控件到裁剪空间(Clip Space)，最后显示到我们的屏幕空间(Screen Space)。为此Unity定义了一系列的宏用来记录这些变换中对应的矩阵：UNITY_MATRIX_M, UNITY_MATRIX_V, UNITY_MATRIX_P以及这些矩阵的逆矩阵和这些矩阵相乘所得的矩阵，这些宏的定义可以在Input.hlsl中找到。
同时Unity也定义了一系列的方便进行坐标转换的函数，可以在SpaceTransforms.hlsl中找到。我的观念是，单纯的使用这些函数虽然能够得到正确的效果，但是仍然需要去深挖这些函数内部的代码，特别是对平台差异化的处理，这样才能知道这些函数的适用范围。
物体空间到世界空间 这里用到的矩阵相对比较简单。我们用\(R\), \(T\)和\(S\)来分别代表物体的旋转平移和缩放系数，\(R\)由物体的三个旋转角决定，这里的格式是一个3x3的矩阵，\(T\)和\(S\)是两个1x3的向量，用\(P\)来代表物体空间的一个点。那么这个点在世界空间中的坐标就可以使用下面的式子进行计算： $$ P_{world} = \begin{pmatrix} R_{00} S_x& R_{01}& R_{02}& T_x \cr R_{10}& R_{11} S_y& R_{12}& T_y \cr R_{20}& R_{21}& R_{22} S_z& T_z \cr 0& 0& 0& 1 \end{pmatrix} \times \begin{pmatrix} P_x \cr P_y \cr P_z \cr 1 \end{pmatrix} $$ 这个4x4的矩阵就是物体空间到世界空间的变换矩阵，这里记为\(M_{o\to w}\)，在\(P\)的基础上额外增加了一个维度的这个向量，是\(P\)对应的齐次坐标。对于普通的向量\(V\)（如物体表面切线方向、视线方向、光源方向）等，从物体空间变换到世界空间时，齐次坐标的高次位应当为0，上式变为： $$ V_{world} = \begin{pmatrix} R_{00} S_x& R_{01}& R_{02}& T_x \cr R_{10}& R_{11} S_y& R_{12}& T_y \cr R_{20}& R_{21}& R_{22} S_z& T_z \cr 0& 0& 0& 1 \end{pmatrix} \times \begin{pmatrix} V_x \cr V_y \cr V_z \cr 0 \end{pmatrix} $$ 要注意的是：将物体空间的法线\(N\)变换到世界空间时，应当使用\(M_{o\to w}\)的逆矩阵的转置\((M_{o\to w}^{-1})^T\)，也就是世界空间到物体空间的变换矩阵的转置\((M_{w\to o})^T\)乘物体空间的法线\((M_{w\to o})^T \times N\)，这条式子等价于\(N \times M_{w\to o}\)。...</p></section><footer class=entry-footer>July 1, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to Unity空间变换总览" href=https://zznewclear13.github.io/posts/unity-space-transformation-overview/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://zznewclear13.github.io/posts/>« Prev Page</a>
<a class=next href=https://zznewclear13.github.io/posts/page/3/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://zznewclear13.github.io/>ZZNEWCLEAR13</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>