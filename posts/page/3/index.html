<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | ZZNEWCLEAR13</title><meta name=keywords content><meta name=description content="这里是zznewclear13的，分享别处找不到的图形学和技术美术相关内容的，个人网站。"><meta name=author content="zznewclear13"><link rel=canonical href=https://zznewclear13.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.min.50ec5873d43aafdb2c832cfa897c60d6e146a48ba3bacc322156221e9661fdc6.css integrity="sha256-UOxYc9Q6r9ssgyz6iXxg1uFGpIujuswyIVYiHpZh/cY=" rel="preload stylesheet" as=style><link rel=preload href=/images/address.png as=image><link rel=preload href=/apple-touch-icon.png as=image><link rel=icon href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zznewclear13.github.io/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://zznewclear13.github.io/favicon.ico><link rel=apple-touch-icon href=https://zznewclear13.github.io/favicon.ico><link rel=mask-icon href=https://zznewclear13.github.io/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><link rel=alternate type=application/rss+xml href=https://zznewclear13.github.io/posts/index.xml><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-157509723-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Posts"><meta property="og:description" content="这里是zznewclear13的，分享别处找不到的图形学和技术美术相关内容的，个人网站。"><meta property="og:type" content="website"><meta property="og:url" content="https://zznewclear13.github.io/posts/"><meta property="og:image" content="https://zznewclear13.github.io/images/address.png"><meta property="og:site_name" content="ZZNEWCLEAR13"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zznewclear13.github.io/images/address.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="这里是zznewclear13的，分享别处找不到的图形学和技术美术相关内容的，个人网站。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zznewclear13.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://zznewclear13.github.io/ accesskey=h title="ZZNEWCLEAR13 (Alt + H)"><img src=/apple-touch-icon.png alt=logo aria-label=logo height=35>ZZNEWCLEAR13</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://zznewclear13.github.io/now/ title=进行时><span>进行时</span></a></li><li><a href=https://zznewclear13.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://zznewclear13.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://zznewclear13.github.io/links/ title=友情链接><span>友情链接</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://zznewclear13.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/VolumetricFog.jpg alt="Volumetric Fog Cover"></figure><header class=entry-header><h2>使用和视锥体对齐的3D纹理来渲染体积雾</h2></header><section class=entry-content><p>为什么要渲染体积雾 因为它就在那里。
当然了，更重要的是因为体积雾能迅速的营造出场景的真实感与氛围感，谁不喜欢光源边上还有一小圈光晕呢，如果什么高亮的物体都能影响体积雾的话，是不是就不太需要bloom效果了呢。我实际地在生活中观察了一下，发现人眼所看到的光晕的效果，是光线进入眼睛之后产生的，也就是说bloom和体积雾确确实实是两种不同的效果。
体积雾的渲染方法 体积雾一般有两种渲染方法，一种是单纯的从相机出发对场景进行Ray Marching，每次进行采样和混合。这种方法主要的缺点是Ray Marching的次数会比较高才能有较好的渲染效果。在我的测试中，开启TAA的时候，20次Ray Marching就能得到很好的体积雾效果了；但是不开启TAA的话，可能会需要60次甚至更高的Ray Marching才能得到和TAA类似的效果。同时，Ray Marching体积雾只能在后处理阶段使用，在处理不写深度的透明物体的时候，会有一些瑕疵。
另一种方法就是使用一张3D纹理，将整个场景的体积雾储存在这张3D纹理中，当绘制物体的时候使用物体的世界空间坐标采样这张3D纹理，直接在片元着色器中计算雾效之后的颜色。这种方法使用的3D纹理会占用更多的内存，但是一定程度上能够正确的渲染所有物体，和60次Ray Marching相比，性能上也说不定会有一些优势。
本文的体积雾实现，参考了EA的寒霜引擎在Siggraph 2015年时的演讲和diharaw的OpenGL的体积雾效果。值得一看的还有Bart Wronski在Siggraph 2014年的演讲，以及之后的荒野大镖客在Siggraph 2019年的课程。使用的是Unity2019.4.29的URP工程。
具体的实现方法 将场景中的需要渲染的雾的信息和阴影信息储存到一张和相机的视锥体对齐的3D纹理中。按照寒霜引擎的做法，纹理大小为(分辨率宽/8)x(分辨率高/8)x64，这样就和屏幕大小的2D纹理占用的内存大小一致了，但我看Unity官方的体积雾工程中，3D纹理的深度为128，就也把自己的设置成128了，纹理深度越深，体积雾的细节就能越高。3D纹理的宽高和视锥体对齐，这很好理解，而这张贴图的纵向深度和实际的深度要怎么对齐呢？最简单的就是和视空间的深度线性对应，但是这会导致近处体积雾的分辨率不够；另一种是和裁剪空间的深度线性对应，经过一些分析可以知道这比之前的方法更糟糕；目前我看下来最好的应该是和视空间的深度指数型对应，这样离相机越近3D纹理的像素会越多，越远则越少。本文只使用了均一的雾，但是可以使用世界空间的坐标、噪波和一系列的运算，计算出某一点的体积雾的浓度。 使用上面的雾的信息和阴影信息计算出散射的值Lscat，从下面的图可以看到Lscat是对所有的光源（本文只有主光源）计算\(f(v, l)Vis(x, l)Li(x, l)\)的和，\(Vis(x, l)\)即为在x点l光的可见性，可以通过采样阴影贴图来获得，\(Li(x, l)\)即为在x点l光的光强，可以简单的计算获得，\(f(v, l)\)用来表述在v的方向观察雾时得到l的散射量，一般被叫做Phase Function，我们使用的是Henyey-Greenstein Phase Function，其中参数g是雾的各向异性的程度，越靠近1表示光线穿过雾时越保持之前的方向，越靠近0表示光线穿过雾时均匀的散射，越靠近-1表示光线穿过雾时越会进行反射（在实际的光照中，我们会去掉\(\pi\)这一项，这样能和Unity的光照模型保持一致）。时空混合也在这一步可以完成。 $$ \tag{Henyey-Greenstein} p(\theta) = \frac 1 {4\pi} \frac {1 - g^2} {(1 + g^2 - 2g \cos \theta)^{\frac 3 2}} $$
对3D纹理从相机近点到远点进行混合，这其实是一种Ray Marching，不过是在3D纹理的纹理空间进行Ray Marching，一次前进一个像素。当混合当前像素和上一个像素时，需要考虑符合物理的透光率(transmittance), \(\varepsilon\)是一个用于归一化的常量，l是两点之间的距离，c是介质的吸收率（一定程度上可以用雾的密度来表示）。具体的混合的计算和说明可以看EA寒霜引擎的PPT第28、29页。 $$ \tag{Beer-Lambert} transmittance = e^{-\varepsilon l c} $$
最终在绘制物体时，使用物体的世界空间的坐标，转换到3D纹理的坐标，采样3D纹理，使用透光率乘上物体本身的颜色，再加上雾的颜色，就得到了最终的体积雾的效果了。 相关代码和说明 VolumetricFog.cs 用于Global Volume中方便添加体积雾和控制各种参数。值得考虑的是maxTransmittance的值，因为相机远裁剪面会比较远，即使雾并不是很大，在最远处也总是能变成单一的颜色，这个值用来防止这种情况，人为地限制了最大不透光率（但是还是叫maxTransmittance）。fogNear这个参数实际是影响了3D纹理和相机之间的距离，最好还是设置成0，不然时空混合时会有一些瑕疵。...</p></section><footer class=entry-footer>August 23, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用和视锥体对齐的3D纹理来渲染体积雾" href=https://zznewclear13.github.io/posts/create-volumetric-fog-using-view-aligned-3d-texture/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/ViewSpaceNormalFromDepthTexture.jpg alt="View Space Normal From Depth Texture Cover"></figure><header class=entry-header><h2>从深度图中获取视空间的法线</h2></header><section class=entry-content><p>为什么要从深度图重建视空间法线 一个很大的应用情景是在后处理的阶段，或是计算一些屏幕空间的效果（如SSR、SSAO等），只能获取到一张深度贴图，而不是每一个几何体的顶点数据，很多的计算中却又需要用到世界空间的法线或者是视空间的法线，这时我们就需要通过深度图来重建视空间的法线。（诶这段话我是不是写过一遍了）
重建视空间法线的方法 bgolus在他的WorldNormalFromDepthTexture.shader里面很全面的介绍了各种重建视空间法线的方法。其中比较值得注意的是来自Janos Turanszki的根据深度差判断当前像素属于哪个平面的方法，和来自吴彧文的横向和纵向多采样一个点来判断当前像素属于哪个平面的方法，其中吴彧文的方法能够在绝大部分情况下获取到最准确的法线（除了尖角的一个像素）。
除了bgolus介绍的方法之外，我在GameTechDev/XeGTAO中还看到了一种方法。这种方法类似于Janos Turanszki的深度差的方法，不过从深度差中获取的是0-1的边缘值（edgesLRTB，edgesLRTB.x越接近0即代表该像素的左侧越是一条边缘），再使用边缘的两两乘积对四个法线进行插值，最终计算出视空间法线。我个人认为当在两个面相接的地方不需要特别准确的法线值时，这是最好的计算法线的方法。用这个方式计算的法线，在两个面相接的地方，法线会有一种从一个面插值到另一个面的效果（且一定程度上抗锯齿），在两个面远近排布的时候，也能获取到准确的法线。
具体的实现方法 根据需要使用的方法，采样深度图。在采样比较集中的情况下，可以使用GatherRed方法来减少采样的次数。GatherRed可以得到双线性采样时的四个像素的R通道的值并封装到一个float4中，当屏幕左下角是(0, 0)时，这个float4的x分量对应采样点左上角的颜色的R通道的值，y对应右上角，z对应右下角，w对应左下角，可以在HLSL的文档中看到Gather的相关介绍。Compute Shader的话可以使用group shared memory进一步减少采样。 使用深度图和当前的uv值计算出像素的视空间的坐标，这一步尤其需要注意视空间坐标Z分量的正负性的问题。Unity的视空间变换矩阵UNITY_MATRIX_V是摄像机位于视空间(0, 0, 0)，看向视空间Z轴负方向的，右手系的矩阵。即视空间的坐标Z分量往往是一个负值，其法线的Z分量在往往下是正值（即画面看上去应该多为蓝色）。 从深度图中计算视空间坐标的时候，如果Unity版本比较旧，会没有UNITY_MATRIX_I_P这个矩阵，这时可以使用unity_CameraInvProjection来代替，但需要注意DirectX平台UV上下翻转的问题。 当屏幕左下角是(0, 0)时，使用右侧的视空间坐标减去左侧的视空间坐标，使用上侧的视空间坐标减去下侧的视空间坐标。五个采样点（包括位于中心的当前像素）可以获得四个向量，对于右手系的视空间坐标来说，将这四个向量按照水平向量叉乘竖直向量的顺序，就可以获得四个当前像素的法线了。 最后使用前面介绍的获取法线的方法，从这四个法线中获取最为正确的法线。这些方法往往都会使用深度值来进行判断，这里需要注意的是透视变换带来的深度的非线性的问题。对于屏幕上等距分布的三个点ABC，当他们在世界空间中处于同一条直线时，有 $$ 2 \cdot rawDepthB = rawDepthA + rawDepthC \newline \frac 2 {linearDepthB} = \frac 1 {linearDepthA} + \frac 1 {linearDepthC} $$ ReconstructNormalComputeShader.compute 使用GatherRed的方法，可以减少ReconstructNormalAccurate所需要的的采样，但是在屏幕的边缘会有一些瑕疵，把采样的sampler改成sampler_LinearRepeat在一定程度上能够解决这些瑕疵。这样的话ReconstructNormalFast需要两次采样，ReconstructNormalAccurate则需要五次采样。 要注意使用边缘信息对法线进行插值的方法，需要先对法线进行归一化，不然叉乘导致前后平面计算出的向量长度会远大于同一平面的向量长度，影响最终的法线。
#pragma kernel ReconstructNormalFast
#pragma kernel ReconstructNormalAccurate
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
#define FEWER_SAMPLES 0
Texture2D&lt;float> _DepthTexture;
RWTexture2D&lt;float4> _RW_NormalTexture;
SamplerState sampler_LinearClamp;
SamplerState sampler_LinearRepeat;
float4 _TextureSize;
float3 GetViewSpacePosition(float2 uv, float depth)
{
#if UNITY_UV_STARTS_AT_TOP
uv....</p></section><footer class=entry-footer>January 27, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 从深度图中获取视空间的法线" href=https://zznewclear13.github.io/posts/get-view-space-normal-from-depth-texture/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/VertexAnimatedPlant.gif alt="Vertex Animated Plant Cover"></figure><header class=entry-header><h2>使用顶点动画制作随风飘动的植物</h2></header><section class=entry-content><p>动机和想要实现的效果 最直接的动机是看了顽皮狗在Siggraph 2016上的PPT，里面介绍了顽皮狗在神秘海域中是如何让植被随风飘荡的。他们介绍了一种将植被的每一部分的pivot的物体空间坐标写到顶点色里，然后在shader中使用这个坐标进行风的效果的计算的方法。较为震撼在风吹过草原时，植被进行弯曲后，草表面的高光会有一种时空上的起伏感（也就是说神秘海域的植被的法线也会被风影响）。所以我也想要借助写pivot的方法来制作植被受到风吹的效果，通过这个方法计算出正确的风吹之后的植被的法线（同时由于法线贴图的存在，还要计算正确的切线）。
稍微翻了一下网上的资料（也没仔细地去搜索），大部分的就是一个普通的顶点动画，有的是用的sin，有的就直接平移。这就产生了第二个需求，植被在顶点动画中应该保持差不多的长度，不然会发现很明显的拉伸的效果。
当然最好还能投射出正常的影子了，这一步只需要把顶点着色器复制一份到投射影子的pass里就可以了。
这里使用的植被模型是MegaScans上的CORDYLINE模型中的var12这个小模型。
难点和相对应的应对方法 Unity的顶点色限制 稍微测试一下就能发现，Unity的顶点色是UNorm8的格式，也就是说无论你在Maya或是3ds Max里导出的模型的顶点色信息是什么样的，导入到Unity中就会变成只有256精度的UNorm8。顽皮狗使用的是自己的引擎，所以它们能够使用全精度的顶点色，但是由于Unity的引擎限制，我们可以考虑到导出pivot的顶点坐标到模型的UV中。
但是很不幸的是，fbx导入到Unity时，即使UV是float4的类型（也就是16bytes)，在Unity中只会识别UV的前两位。所以只能无奈的将pivot的顶点坐标（float3的数据）储存到两个UV的三个通道里，同时将pivot的层级存到剩下的一个通道里。我不知道顽皮狗具体是怎么计算pivot的层级关系的，他在PPT中写的是无需计算，但我在实际操作中只能一层一层的算（而且只能算两层），也希望知道具体怎么操作的人告知一下方法。
所以接下来要做的是在Maya中把pivot的物体空间坐标和pivot的层级写到对应顶点的某两套UV中，本文是写到第二套和第三套UV中（也就是TEXCOORD1和TEXCOORD2）。于是我恶补了一下maya的python脚本的写法，不过在写数值到UV中时，又遇到了一个小问题。Maya的cmds.polyEditUV这个方法，明明能传入uvSetName这个参数，用于操作对应的UV，但我实际使用时只能写数值到当前的UV中，导致最后写的脚本只能僵硬的操作当前UV，每次切换UV时需要重新修改脚本再运行一次。
最终的脚本是这样的：
VertexPivotWriteTool.py import maya.cmds as cmds targetVertexStr = "Select any vertex to start." vertexColorStr = "Select any vertex to start." pivotPosition = [0.0, 0.0, 0.0] def ui(): if cmds.window("VertexPivotWriteTool", exists = True): cmds.deleteUI("VertexPivotWriteTool") global targetVertexStr global targetVertexField global vertexColorStr global vertexColorField global pivotLayer vertexPivotWindow = cmds.window("VertexPivotWriteTool", widthHeight = [500, 400]) form = cmds.formLayout(numberOfDivisions = 100) pivotLayerLable = cmds.text("Pivot Layer (0 for root pivot)") pivotLayer = cmds....</p></section><footer class=entry-footer>January 6, 2022&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 使用顶点动画制作随风飘动的植物" href=https://zznewclear13.github.io/posts/create-plant-swaying-in-wind-using-vertex-animation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/EqualWidthBezierCurve.jpg alt="Equal Width Bezier Curve"></figure><header class=entry-header><h2>在Unity的UI中绘制等宽的贝赛尔曲线</h2></header><section class=entry-content><p>动机和贝塞尔曲线相关的背景知识 动机当然是要在UI上绘制一个贝塞尔曲线的形状了，想做的效果大概就和虚幻引擎蓝图连接节点的线差不多了。这里要绘制的是一种较为特殊的贝塞尔曲线，它的两个端点的切线是水平的，且拥有旋转对称的特性。
我们想要绘制的S形曲线是三阶的贝塞尔曲线。三阶贝塞尔曲线有四个控制点\(P_0, P_1, P_2, P_3\)，对于一个从0到1的变量\(t\)，贝塞尔曲线的做法是对这四个点按照顺序以\(t\)做插值生成三个新的点，然后对这三个点按照顺序以\(t\)做插值生成新的两个点，再对这两个点以t做插值生成最后的点，当t在0到1中变化时，这个点的轨迹就构成了贝塞尔曲线。贝塞尔曲线上的点可以用四个控制点和\(t\)来表示： $$ P_{bezier} = P_0 \cdot (1 - t)^3 + 3 P_1 \cdot (1 - t)^2 \cdot t + 3 P_2 \cdot (1 - t) \cdot t^2 + P_3 \cdot t^3 $$
如果初始四个点分别是(0.0, 1.0), (d, 1.0), (1.0 - d, 0.0)，和(1.0, 0.0)的话，也就是我们所要绘制的特殊的贝塞尔曲线，可以算出贝塞尔曲线的坐标为 $$ P_{bezier} = ((3 t - 9t ^ 2 + 6t^3) \cdot d + 3t^2 - 2t^3, 1 - 3t^2 + 2t^3) $$ 但是即使得到了贝塞尔曲线的参数方程，想要将其表达成\(f(x)\)的形式仍然是相当困难的。Alan Wolfe在他的博客中提到了一种一维贝塞尔曲线，也是一种贝塞尔曲线的特殊情况，四个控制点在水平方向上等距排开，这样子贝塞尔曲线的参数方程的水平分量就刚好是\(t\)，它的竖直分量也就是我们需要的\(f(x)\)。唯一美中不足的是，能轻易得到\(f(x)\)的一维贝赛尔曲线，往往是一个“躺倒”的贝赛尔曲线，感官上看上去是横着的，Shadertoy上有相关的演示。但这种一维贝塞尔曲线又有一种特殊情况，也就是前两个控制点的竖直高度相等，后两个控制点的竖直高度也相等，这时这种特殊的一维贝塞尔曲线就是我们耳熟能详的smoothstep曲线了（数学真奇妙啊）。可惜smoothstep不能满足我们随意控制曲线形状的需求，只能另求他法。...</p></section><footer class=entry-footer>December 15, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 在Unity的UI中绘制等宽的贝赛尔曲线" href=https://zznewclear13.github.io/posts/draw-equal-width-bezier-curve-in-unity/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://zznewclear13.github.io/posts/images/EqualWidthOutline.jpg alt="Equal Width Outline Cover"></figure><header class=entry-header><h2>在Unity中绘制等宽的描边</h2></header><section class=entry-content><p>对于描边的思考 描边可以说是一个特别关键的效果，不仅仅是二次元卡通渲染需要用到描边，在用户交互的方面，描边也是一个增强用户交互的关键效果。
一般的描边的做法是绘制一个沿物体空间顶点法线（或是记录在顶点色中的描边方向）外扩的模型背面，这种做法在绝大部分情况都看上去不错，但是描边的深度测试会有一些小瑕疵，同时在物体距离摄像机较近的时候，描边会显得较粗，此外这种描边没有抗锯齿的效果，绘制模型的背面也让造成了性能的浪费。另外一种方法是使用Multiple Render Targets，渲染出一个模型的剪影，然后使用类似高斯模糊的办法，对采样进行偏移，这样可以渲染出一个较好的可以有抗锯齿效果的描边，但是仅限于模型向外的描边，缺少模型内部的描边效果。
最好的描边应该是能够支持模型外描边、内描边、材质描边的描边效果，pencil +实现了这些效果，但是效率不是很高，这里有相关的演示（我也是看了这个之后才决定用安吉拉的模型的）。我看到的较好的方案应该还是L-灵刃的使用退化四边形生成描边的办法，github上也分享了源码。
这篇博客中介绍的描边，是基于我上一篇博客中讲的世界空间中绘制等宽线条的方法，使用DrawProcedural绘制的等宽的描边。我认为只有等宽的描边，才是最能表现二次元画面特征的描边。这里的“等宽”，并不是说线条的宽度处处相等，线条当然可以控制每一部分的粗细，但是这个控制的粗细是基于一个固定值的相对粗细（也就是存在顶点色中的描边粗细值），当粗细值相同时，不管是画面的哪个部分的描边的粗细（不管是内描边还是外描边），都应该是相同的。
实现描边时需要注意的点 首先参考退化四边形的案例，需要先对模型文件进行预处理。这里我做了简化，只去寻找两个三角面共用的边，忽略了只属于一个三角面的边的情况（事实上我觉得这样看上去的视觉效果也蛮不错的）。一条共用边对应了这条边的两个顶点，两侧的两个三角形和这两个三角形对应的额外的两个顶点。这里都用序号来表示，需要6个int值（事实上可以忽略两个三角形的编号，就能存在一个int4里了）。判断一条边共同属于两个三角形，就相当于判断两个三角形中的某两个顶点的序号是相同的（实际上顺序是相反的）。但是实际操作中，即使是相同的顶点，在两个三角形中顶点的序号也不一定是相同的，因此需要先把两个相同的顶点（使用距离来判断）合并成一个顶点，这也就是我使用vertRemapping这个数组的目的。剩下的就是循环所有三角形，获取共用边的算法部分了，尽可能的优化一下，不然三角面一多运算的时间要很久。
有了共用边的数据，通过SkinnedMeshRenderer.BakeMesh()可以获取到当前帧每个顶点的物体空间的坐标，就能进行描边的计算了。使用DrawProcedural时顶点的数量可以是公用边数量的两倍，这样需要在Geometry Shader中把顶点数目从2扩充到6，或者是在绘制时将顶点数量设置成共用边数量的六倍，可能后者效率会高一点，不过思考的时候会有点乱，这里就使用Geometry Shader的方法了。
如果是像之前的博客介绍的，以共用边两个顶点为中心，同时向左右两侧外扩的话，会因为深度测试的原因，导致描边部分被模型遮挡，这个问题比较严重，他直接导致了外描边和内描边的粗细不一样，也导致了在一条描边中会露出一部分模型的问题。这里采用的方法是仅向外侧描边，在计算是不是轮廓边的时候同时计算需要描边的方向，使用这个方向向外扩展描边，最后效果还蛮不错的。
要实现风格化描边的话，除了使用顶点色来控制描边的粗细之外，还能使用一张贴图作为描边的笔刷，在绘制描边的时候采样这张贴图，本篇博客就暂不使用这种方法了。
具体的实现描边的操作 对当前模型获取到所有的共用边对应的四个顶点序号，严格保持顺序！ 每一帧使用SkinnedMeshRenderer.BakeMesh，获取所有顶点当前的物体空间的坐标。 传入顶点坐标，顶点重映射数组，共用边信息，如果需要的话还要传顶点色到描边的Shader中。 使用DrawProcedural绘制描边，顶点数量为共用边的数量的两倍。 在顶点着色器中，计算共用边四个顶点的裁剪空间（实际上用的是屏幕空间）的坐标，判断这条边是不是轮廓边，同时记录描边外扩的方向，相当于对于每一条边（每两个点）存两个bool变量。 在几何体着色器中，计算共用边两个顶点的屏幕空间的坐标，计算出两个点之间的向量，计算与之相垂直的外扩的方向，根据两个向量，计算出描边的四个顶点的裁剪空间的坐标，并赋予uv的值。 在片元着色器中，根据uv计算出描边的颜色，可以采样贴图，也可以直接返回计算的颜色。 由于整个描边的操作较为复杂，我尽可能多的写了注释。
OutlineObject.cs 定义共用边的结构体，也定义用于保存共用边数据的ScriptableObject。
using UnityEngine; namespace ZZNEWCLEAR13.Outline { [System.Serializable] public class OutlineObject : ScriptableObject { [System.Serializable] public class MeshOutlineInfo { public string meshName; //尽量不要都显示出来，不然很卡。。 //顶点、法线、切线和顶点色 [HideInInspector] public Vector3[] vertices; [HideInInspector] public Vector3[] normals; [HideInInspector] public Vector4[] tangents; [HideInInspector] public Color[] colors; //vertRemapping把相同位置的顶点编号映射到第一个该位置顶点的编号 [HideInInspector] public int[] vertRemapping; //三角形对应的顶点编号 [HideInInspector] public Vector3Int[] triangles; public Line[] commonLines; } public MeshOutlineInfo outlineInfo; } [System....</p></section><footer class=entry-footer>December 12, 2021&nbsp;·&nbsp;zznewclear13</footer><a class=entry-link aria-label="post link to 在Unity中绘制等宽的描边" href=https://zznewclear13.github.io/posts/draw-equal-width-outline-in-unity/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://zznewclear13.github.io/posts/page/2/>« Prev Page</a>
<a class=next href=https://zznewclear13.github.io/posts/page/4/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://zznewclear13.github.io/>ZZNEWCLEAR13</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>